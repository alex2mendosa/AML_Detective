{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By chat model we mean LLM model which operates with chats \n",
    "import os \n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "import threading\n",
    "\n",
    "from langchain_openai import ChatOpenAI \n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal , Optional\n",
    "\n",
    "## check performance in agent workflow \n",
    "from typing import TypedDict, Annotated, List, Dict, Optional\n",
    "from langchain_core.messages import BaseMessage, AnyMessage, ToolMessage,HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph import add_messages , START, END , StateGraph\n",
    "from IPython.display import Image, display \n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# prepare model for embeddings  \n",
    "from langchain_openai import OpenAIEmbeddings \n",
    "from langchain_core.tools import tool, StructuredTool\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np \n",
    "import numpy.typing as npt\n",
    "\n",
    "from tavily import TavilyClient \n",
    "\n",
    "import subprocess\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "## OpenAI configuration\n",
    "api_key_var = os.environ.get(\"OPENAI_API_KEY\")\n",
    "#print(\"OpenAI API: \" , api_key_var)\n",
    "\n",
    "\n",
    "# keys for tavily \n",
    "tavily_api = os.environ.get(\"TAVILY_API_KEY\")\n",
    "#print(\"Tavily API: \" , tavily_api)\n",
    "\n",
    "# api for goole\n",
    "api_google = os.environ.get('GOOGLE_API_KEY')\n",
    "#print(\"Google API: \" , api_google)\n",
    "\n",
    "# define search engine\n",
    "SEARCH_ENGINE_ID = '26dda816634bd4044'\n",
    "\n",
    "\n",
    "## word count \n",
    "def count_words_whitespace(s: str) -> int:\n",
    "    return len(s.split())\n",
    "\n",
    "class WordCounter:\n",
    "    def __init__(self, word_in: int = 0, word_out: int = 0):\n",
    "        self.word_input = word_in\n",
    "        self.word_output = word_out\n",
    "\n",
    "    def add_word_in(self, text: str) -> None:\n",
    "        self.word_input += count_words_whitespace(text)\n",
    "\n",
    "    def add_word_out(self, text: str) -> None:\n",
    "        self.word_output += count_words_whitespace(text)\n",
    "\n",
    "\n",
    "counter = WordCounter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245000b5",
   "metadata": {},
   "source": [
    "#### Test OpenAI SDK - Azure Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = ChatOpenAI(\n",
    "#    model=\"gpt-4.1\",  # ← Set once here\n",
    "#    base_url=endpoint, api_key=api_key\n",
    "#)\n",
    "  # Model configured once\n",
    "  # Every call uses the same model\n",
    "  # Good for consistent chains/agents\n",
    "  # note # BadRequestError: Error code: 400 - {'error': {'code': 'unknown_model', 'message': 'Unknown model: gpt-3.5-turbo', 'details': 'Unknown model: gpt-3.5-turbo'}}\n",
    "    # 3.5 is default but it must be created as asset\n",
    "\n",
    "#client = OpenAI(\n",
    "#    base_url=endpoint, api_key=api_key )\n",
    "\n",
    "#response = client.chat.completions.create(\n",
    "#    model=\"gpt-4.1\",  # ← Must specify each call\n",
    "#    messages=[...] )\n",
    "\n",
    "  # One client, many models\n",
    "  # Flexible per request\n",
    "  #Good for dynamic model switching\n",
    "\n",
    "## Commants on endpoins\n",
    "endpoint = 'https://datam-mhtcc5x5-westeurope.cognitiveservices.azure.com/openai/v1'\n",
    "# The SDK automatically appends /chat/completions and other paths\n",
    "\n",
    "# azure https://datam-mhtcc5x5-westeurope.cognitiveservices.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview\n",
    "# This is the direct REST API endpoint, Used for raw HTTP requests (curl, requests library, etc.)\n",
    "\n",
    "api_key_azure_41 = os.environ.get('OPENAI_API_KEY_AZURE_41')\n",
    "print(f\"API Key loaded: {api_key_azure_41[:3]}...\" if api_key_azure_41 else \"Not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare embedding model\n",
    "embedding_main = OpenAIEmbeddings(api_key=api_key_var, model=\"text-embedding-3-small\")\n",
    "embedding_cross_lang = OpenAIEmbeddings(api_key=api_key_var, model=\"text-embedding-3-large\")\n",
    "\n",
    "# For HyDE comparison we will employ large embedding model for richer semantic representation\n",
    "# Larger model should be able to capture same concepts in different languages \n",
    "# Similar concepts should be positioned closer in the vector space\n",
    "\n",
    "# Test with similar concepts + unrelated text\n",
    "test_sentences = [\n",
    "    \"Искусственный интеллект меняет мир\",        # AI is changing the world (Russian)\n",
    "    \"Artificial intelligence is changing the world\",  # AI is changing the world (English) - fixed typo \"word\" -> \"world\"\n",
    "    \"Я люблю есть пиццу по вечерам\"              # I love eating pizza in the evenings (unrelated)\n",
    "]\n",
    "\n",
    "# Get embeddings\n",
    "#embeddings = [np.array(embedding_cross_lang.embed_query(x)).reshape(1, -1) for x in test_sentences]\n",
    "\n",
    "# Calculate similarities\n",
    "#print(\"Similarity between Russian and English (should be HIGH):\")\n",
    "#print(f\"  {cosine_similarity(embeddings[0], embeddings[1])[0][0]:.4f}\")\n",
    "\n",
    "#print(\"\\nSimilarity between Russian AI and Pizza (should be LOW):\")\n",
    "#print(f\"  {cosine_similarity(embeddings[0], embeddings[2])[0][0]:.4f}\")\n",
    "\n",
    "#print(\"\\nSimilarity between English AI and Pizza (should be LOW):\")\n",
    "#print(f\"  {cosine_similarity(embeddings[1], embeddings[2])[0][0]:.4f}\")\n",
    "\n",
    "#del embeddings\n",
    "\n",
    "# large vs small:\n",
    "# better at capturing same meaning in different languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd7fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to python 4_5_2_research_assistant.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9481b07e",
   "metadata": {},
   "source": [
    "#### LLM models api definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287bb4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to create payload \n",
    "llm_payload = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",  \n",
    "    temperature=0.2,     \n",
    "    max_tokens=500,      \n",
    "    top_p=0.95,          \n",
    "    timeout=15,         \n",
    ")\n",
    "\n",
    "\n",
    "## we also need to generate names variations in different languages\n",
    "llm_names_variation = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",   # note the hyphen\n",
    "    temperature=0.0,        # pure extraction/translation\n",
    "    timeout=30,\n",
    "    max_retries=3,\n",
    "    max_tokens=50          # we only need one short line\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Translation and key terms extraction from short input\n",
    "llm_translation_or_terms = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",  # BEST: Cheapest model that excels at translation tasks\n",
    "                          # Translation is pattern-matching, doesn't need reasoning power\n",
    "                          # GPT-4o-mini handles languages perfectly at 10x lower cost\n",
    "    \n",
    "    temperature=0.1,      # BEST: Near-deterministic output for consistent translations\n",
    "                          # Translation should be consistent, not creative\n",
    "                          # 0.1 allows tiny variation while preventing hallucinations\n",
    "    \n",
    "    max_tokens=500,       # BEST: Perfect for short translations and key terms\n",
    "                          # Prevents model from over-explaining or adding fluff\n",
    "                          # Saves money by limiting output length\n",
    "    \n",
    "    timeout=5,           # BEST: Translation should be fast, 5s is generous\n",
    "                          # If it takes longer, something's wrong with the request\n",
    "                          # Prevents hanging requests from eating budget\n",
    "    \n",
    "    max_retries=2         # BEST: Translation usually works first try\n",
    "                          # 2 retries handles temporary network issues\n",
    "                          # More retries waste time and money on bad requests\n",
    ")\n",
    "\n",
    "# # generate persona\n",
    "llm_class_generation = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",     # BETTER: Cheaper, perfectly capable for structured output\n",
    "    temperature=0.2,         # BEST: Near-deterministic for consistent structure\n",
    "    max_tokens=1000,         \n",
    "    timeout=60,             \n",
    "    max_retries=2           # ADEQUATE: Structured output usually works first try\n",
    ")\n",
    "# LengthFinishReasonError: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=200, prompt_tokens=426, total_\n",
    "# APITimeoutError: Request timed out.\n",
    "# 4.0 mini replaced with 4.1 as it offers larger context allowing to simulate more experts\n",
    "\n",
    "\n",
    "llm_hyde_generation = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",     # OPTIMAL: Cost-effective for creative writing\n",
    "    temperature=0.5,         # BEST: Creative variation for different journalist styles\n",
    "    max_tokens=500,          \n",
    "    timeout=60,            \n",
    "    max_retries=2          \n",
    ")\n",
    "\n",
    "\n",
    "########################################### AZURE\n",
    "# Error generating reputation summary: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your \n",
    "# prompt and retry. To learn more about our content filtering policies please read our documentation:\n",
    "# https://learn.microsoft.com/en-us/answers/questions/1297066/i-keep-getting-this-error-exception-in-chat-messag\n",
    "\n",
    "#Error generating reputation summary: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': \n",
    "#'Your requests to gpt-4.1 for gpt-4.1 in West Europe have exceeded the token rate limit for your current AIServices S0 pricing tier. This request was for ChatCompletions_Create under OpenAI Language Model Instance API. Please retry after 60 seconds. To increase your default rate limit, visit: https://aka.ms/oai/quotaincrease.'}}\n",
    "\n",
    "# Summary of content extracted from URL with tavily, applieed per each link\n",
    "llm_url_content_summary = ChatOpenAI(\n",
    "    base_url = f\"{endpoint}\" , \n",
    "    api_key = api_key_azure_41 , \n",
    "    model=\"gpt-4.1\",  # BETTER CHOICE: Your original \"gpt-4o\" was budget-killer\n",
    "                          # URL content analysis is mostly extraction/summarization\n",
    "    \n",
    "    temperature=0.2,      # BEST: Factual analysis needs consistency, not creativity\n",
    "    max_tokens=1500,     \n",
    "    top_p=0.95,         \n",
    "    timeout=15          \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Applied for extract_evidence_claims, consolidates results from Multiple summaries\n",
    "llm_agg_summaries = ChatOpenAI(\n",
    "    base_url = f\"{endpoint}\" , \n",
    "    api_key = api_key_azure_41 , \n",
    "\n",
    "    model=\"gpt-4.1\",      \n",
    "                          # Multi-document synthesis requires intelligence\n",
    "                          # Finding connections across articles needs advanced reasoning\n",
    "                          # 128K context window handles multiple long articles\n",
    "                          # This is where you should spend your budget\n",
    "    \n",
    "    temperature=0.1,      # BEST: Even complex analysis should be consistent\n",
    "                          # You want reliable insights, not creative interpretations\n",
    "    \n",
    "    max_tokens=3000,     \n",
    "    top_p=0.95,          # GOOD: Allows sophisticated language while staying accurate\n",
    "    timeout=60,          \n",
    "    max_retries=3        \n",
    ")\n",
    "\n",
    "\n",
    "# Model uses multiple summaries to make conclusion about possible risk \n",
    "llm_evaluation = ChatOpenAI( # compare to 4.o should have better instrusction following\n",
    "    base_url = f\"{endpoint}\" , \n",
    "    api_key = api_key_azure_41 , \n",
    "    model=\"gpt-4.1\", # BadRequestError: Error code: 400 - {'error': {'code': 'unknown_model', 'message': 'Unknown model: gpt-4.o', 'details': 'Unknown model: gpt-4.o'}}      \n",
    "    temperature=0.2,                   \n",
    "    max_tokens=3000,     \n",
    "    #top_p=0.95,         \n",
    "    timeout=1000,          \n",
    "    max_retries=3        \n",
    ")\n",
    "# BadRequestError: Error code: 400 - {'error': {'message': \"Unsupported parameter: 'top_p' is not supported with this model.\", \n",
    "# 'type': 'invalid_request_error', 'param': 'top_p', 'code': 'unsupported_parameter'}}\n",
    "\n",
    "## test gpt 5, takes signifficnt time, requires larger timeout\n",
    "# result = llm_evaluation.invoke(\"Generate recommendations on how to prepare banana bread\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb04c2d",
   "metadata": {},
   "source": [
    "#### Variations of company names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00918aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now genetate variation names \n",
    "import re\n",
    "def generate_name_regex(company_name: str, llm) -> tuple[str, list[str], re.Pattern]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        pipe_line: \"Original | Russian\"\n",
    "        parts: [Original, Russian]\n",
    "        name_re: compiled regex matching either variant (case-insensitive)\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert at generating a single-line string of company name variants separated by '|'.\n",
    "\n",
    "    OUTPUT FORMAT (choose exactly one based on spaces in the Original name):\n",
    "    - If the Original name CONTAINS whitespace:\n",
    "    <ORIGINAL_NAME>|<RUSSIAN_NAME>|<ORIGINAL_NO_SPACES>|<RUSSIAN_NO_SPACES>\n",
    "    - If the Original name DOES NOT CONTAIN whitespace:\n",
    "    <ORIGINAL_NAME>|<RUSSIAN_NAME>\n",
    "\n",
    "    Rules:\n",
    "    - ORIGINAL_NAME = the input company name verbatim (do not modify punctuation, casing, or suffixes).\n",
    "    - RUSSIAN_NAME = a **transliteration/phonetic rewrite** of ORIGINAL_NAME into Cyrillic. **Do NOT translate any words** (brand words, common nouns, legal suffixes, country names, etc.). Only rewrite letters to approximate English pronunciation. If the input is already Cyrillic/Russian, repeat it verbatim. If unsure, copy the original as is.\n",
    "    - ORIGINAL_NO_SPACES = ORIGINAL_NAME with ALL whitespace removed (preserve punctuation/casing). Include ONLY if the Original name contains whitespace.\n",
    "    - RUSSIAN_NO_SPACES = RUSSIAN_NAME with ALL whitespace removed (preserve punctuation/casing). Include ONLY if the Original name contains whitespace.\n",
    "    - Preserve hyphens, punctuation, and casing exactly where they appear in ORIGINAL_NAME.\n",
    "    - Output MUST be exactly one line, no leading/trailing spaces, no extra spaces around '|', no quotes, no notes, no extra variants, no newlines.\n",
    "\n",
    "    Original name: {company_name}\n",
    "    \"\"\".strip()\n",
    "\n",
    "\n",
    "    resp = llm.invoke(prompt)\n",
    "    pipe_line = (getattr(resp, \"content\", \"\") or \"\").strip()\n",
    "\n",
    "    # Parse \"Original | Russian\", fallback to original if needed\n",
    "    parts = [p.strip() for p in pipe_line.split(\"|\")]\n",
    "\n",
    "    # Compile strict, case-insensitive pattern\n",
    "    pattern_str = r\"(?:%s)\" % \"|\".join(map(re.escape, parts))\n",
    "    name_re = re.compile(pattern_str, re.IGNORECASE)\n",
    "\n",
    "    return parts, name_re\n",
    "\n",
    "\n",
    "## test \n",
    "parts, name_re = generate_name_regex(\"Danube Logistics\", llm_names_variation)\n",
    "print(\"Variants:\", parts)\n",
    "\n",
    "tests = [\n",
    "    \"Our vendor is Danube Logistics for Q4.\",\n",
    "    \"Our vendor is DANUBE LOGISTICS for Q4.\",\n",
    "    \"our vendor is danube logistics for q4.\",\n",
    "    \"Payment processed for DanubeLogistics yesterday.\",\n",
    "    \"PAYMENT PROCESSED FOR DANUBELOGISTICS YESTERDAY.\",\n",
    "    \"payment processed for danubelogistics yesterday.\",\n",
    "    \"He said \\\"Danube Logistics\\\" will handle shipping.\",\n",
    "    \"Contract signed with DanubeLogistics, terms apply.\",\n",
    "    \"Partners — Danube Logistics — confirmed attendance.\",\n",
    "    \"Client=DanubeLogistics; status=active.\",\n",
    "]\n",
    "\n",
    "for i, s in enumerate(tests, 1):\n",
    "    print(f\"{i:02d}. {'MATCH' if name_re.search(s) else 'NO MATCH'} — {s}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cede84",
   "metadata": {},
   "source": [
    "#### Main classes for workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe052d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Support for journalists and HyDe articles \n",
    "\n",
    "class Journalist(BaseModel):\n",
    "    expertise: str = Field(\n",
    "        description=\"Primary area of expertise and writing focus.\"\n",
    "    )\n",
    "    perspective: str = Field(\n",
    "        description=\"Writing perspective and approach to the topic.\"\n",
    "    )\n",
    "    style: str = Field(\n",
    "        description=\"Writing style, tone, and target audience.\"\n",
    "    )\n",
    "\n",
    "class HydePerspectives(BaseModel):\n",
    "      journalists: List[ Journalist ] = Field( \"Comprehensive list of analysts with their roles and affiliations.\" )\n",
    "\n",
    "## test generation of personalitis \n",
    "journalist_instructions = \"\"\"\n",
    "\n",
    "You are creating exactly {max_journalists} AI journalist personas to analyze \n",
    "the SAME financial-crime topic from DIFFERENT, NON-OVERLAPPING angles for banking risk assessment.\n",
    "\n",
    "Topic under investigation: {crime_topic}\n",
    "Goal: Create persona of journalist which has solid experience in writing articles which occuses company over involement in  {crime_topic}.\n",
    "\n",
    "OUTPUT FORMAT (MANDATORY)\n",
    "- Return ONLY a valid HydePerspectives object with exactly {max_journalists} journalists.\n",
    "- Each journalist has exactly these fields:\n",
    "  - expertise (short phrase)\n",
    "  - perspective (2-3 sentences)\n",
    "  - style (6-10 adjectives/descriptors, comma-separated)\n",
    "- No extra commentary, headings, or prose.\n",
    "\n",
    "For each journalist:\n",
    "- expertise: Their specific risk assessment specialization\n",
    "- perspective: From what perspective they asses the impact of crime over diffenret economical or social aspects\n",
    "- style: Their analytical approach to uncovering risks relevant to banking partnerships\n",
    "\n",
    "UNIQUENESS REQUIREMENTS (MANDATORY)\n",
    "- Pairwise distinct expertise (not just synonyms; avoid generic labels like “risk analyst”).\n",
    "- Pairwise distinct perspectives (each must emphasize different indicators/decision criteria).\n",
    "- style must contain 3–6 tokens; at least TWO tokens must be unique to that persona (not used by any other persona).\n",
    "- Before returning, self-check all pairs. If any two personas substantially overlap in expertise keywords OR share >50% of style tokens OR rephrase the same perspective, REVISE and re-check.\n",
    "\n",
    "COVERAGE & DIVERSITY (GUIDANCE, THEN ENFORCE UNIQUENESS)\n",
    "- Distribute personas across different risk axes. Draw from (but are not limited to):\n",
    "  • Regulatory/Enforcement (sanctions, consent orders, investigations)\n",
    "  • Financial/Forensic flows (counterparties, anomalies, cash-intensity)\n",
    "  • Operational/Governance/TPRM (controls, third parties, processes)\n",
    "  • Reputational/Media/Stakeholders (controversy persistence, sentiment)\n",
    "  • KYC/AML/BO/PEP/Sanctions screening (beneficial ownership transparency)\n",
    "  • Correspondent banking & cross-border exposure\n",
    "  • Data privacy/consumer protection\n",
    "  \n",
    "- If {max_journalists} ≥ 5, ensure at least one persona implicitly covers each of these example \n",
    "  archetypes (use them as inspiration; do NOT output role names, reflect them via fields only):\n",
    "  1) Regulatory Compliance Analyst — statutory/enforcement exposure\n",
    "  2) Financial Due Diligence Investigator — flows/counterparties/anomalies\n",
    "  3) Operational Risk Assessor — governance/controls/third-party risk\n",
    "  4) Reputational Risk Evaluator — media patterns/controversy persistence\n",
    "  5) KYC/AML Specialist — KYC gaps/BO transparency/PEP & sanctions\n",
    "- If {max_journalists} < 5, prioritize coverage in this order: KYC/AML → Regulatory → Financial.\n",
    "\n",
    "FIELD WRITING RULES\n",
    "- expertise: one crisp, specific phrase tied to the angle (no generic titles).\n",
    "- perspective: 1–2 sentences listing the key indicators/thresholds/heuristics used to decide on partnership risk (e.g., “weights unresolved consent orders more than remedial plans”).\n",
    "- style: 3–6 concise descriptors shaping tone/approach (e.g., “forensic, evidence-driven, regulation-centric, conservative”). Ensure ≥2 tokens unique to this persona.\n",
    "\n",
    "Return ONLY the HydePerspectives object with exactly {max_journalists} journalists.\"\"\"\n",
    "\n",
    "\n",
    "#system_message = journalist_instructions.format( crime_topic = \"money laundering\" , max_journalists= 1)\n",
    "#structured_llm = llm_class_generation.with_structured_output( HydePerspectives )\n",
    "\n",
    "# populate values  \n",
    "#journalists = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=\"Generate the set of journalists according to instructions\")])\n",
    "\n",
    "# hasattr(journalists,\"journalists\")\n",
    "#journalists.model_dump()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evidence Lineage tracking \n",
    "AllowedClaimType = Literal[\"allegation\",\"investigation\",\"charge\",\"conviction\",\"plea\",\"fine\",\"settlement\",\"clearance\",\"sanction_listing\",\"other\"]\n",
    "\n",
    "class EvidenceClaim(BaseModel):\n",
    "    \"\"\"Track claims extracted from summaries - focused on consolidation\"\"\"\n",
    "    claim_text: str = Field(description=\"Specific claim made (e.g., 'FinCEN fined company €50M in 2023')\")\n",
    "    claim_type: AllowedClaimType = Field(description=\"Each article must fit specific only 1 claim type\") # should be generated during classification\n",
    "    supporting_urls: List[str] = Field(description=\"ALL URLs that mention this claim\")\n",
    "    date_publish: str = Field(description=\" Publication date or event date \")\n",
    "\n",
    "\n",
    "class ClaimsFromSummaries( BaseModel ): \n",
    "    evidence_claims: List[EvidenceClaim] = Field(\n",
    "    description=\"All extractable claims from the summaries\"\n",
    "      )\n",
    "\n",
    "# Accountability: Every claim is traced to specific source\n",
    "# Credibility: Check if the claim is supported by evidence\n",
    "# Gap identification: We know what information is missing from the data\n",
    "# Iteration: Check how many times we researched missing evidences \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49492845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and Meta for extracted content, per single link\n",
    "class LinkCollection(BaseModel):\n",
    "       displayLink: str = Field(description=\"The display URL shown in search results (usually domain name)\")\n",
    "       link: str = Field(description=\"The full URL of the search result\")\n",
    "       raw_content: str = Field(default=\"\", description=\"Content extracted from URL\")\n",
    "       summary: str = Field(default=\"\", description=\"Summary of content extracted from URL\")\n",
    "       claim_type: str = Field(default=\"other\", description=\"Each article must fit specific only 1 claim type\")\n",
    "       date_published: Optional[str] = Field( default=None, description=\"Publication date extracted from content (format: YYYY-MM-DD, or 'Unknown' if not found)\" )\n",
    "       \n",
    "       hyde_score: Optional[float] = Field(\n",
    "        default=None,\n",
    "        description=\"Max value of similarity between content of web page and HyDe articles\"\n",
    "    )\n",
    "       \n",
    "#ContentSummary (claim_type: AllowedClaimType) \n",
    "#    ↓ [extract/convert]\n",
    "#LinkCollection (claim_type: str)       \n",
    "       \n",
    "# during article summarizations we generate both summary and assign specific claim  type    \n",
    "\n",
    "class ContentSummary(BaseModel):\n",
    "    claim_type: AllowedClaimType = Field(\n",
    "        description=\"Primary financial crime classification from content\"\n",
    "    )\n",
    "\n",
    "    date_published: Optional[str] = Field( default=None,\n",
    "    description=\"Publication date extracted from content (format: YYYY-MM-DD, or 'Unknown' if not found)\" )\n",
    "\n",
    "    summary: str = Field(\n",
    "        description=\"Detailed summary of financial crime/compliance information present in the content, or statement that no relevant information exists\"\n",
    "    )\n",
    "    \n",
    "\n",
    "## test structured output\n",
    "\n",
    "url_summary_instructions = '''\n",
    "You are analyzing RAW CONTENT extracted by Tavily to determine if it contains financial crime/compliance information.\n",
    "Target entity: \"{entity_name}\"\n",
    "\n",
    "TASK 1 - EXTRACT DATE (date_published field):\n",
    "Find the publication date or event date in the content:\n",
    "- Look for: publication date, article date, press release date, or event date\n",
    "- Format as: YYYY-MM-DD (e.g., \"2023-05-15\")\n",
    "- If multiple dates exist, prefer the publication date over event dates\n",
    "- If no clear date is found, use: \"Unknown\"\n",
    "- Common date locations: header, byline, footer, or first paragraph\n",
    "\n",
    "TASK 2 - CLASSIFY (claim_type field):\n",
    "Determine the PRIMARY claim type from the content:\n",
    "- allegation: Unproven accusations or allegations of wrongdoing\n",
    "- investigation: Active investigations, probes, or inquiries  \n",
    "- charge: Formal criminal or civil charges filed\n",
    "- conviction: Guilty verdicts, convictions, or findings of liability\n",
    "- plea: Plea agreements, admissions, or guilty pleas\n",
    "- fine: Monetary penalties, fines, or financial sanctions imposed\n",
    "- settlement: Settlements, resolved cases, or negotiated agreements\n",
    "- clearance: Exonerations, dismissals, or cases dropped/closed without findings\n",
    "- sanction_listing: Sanctions designations, blacklisting, or regulatory listings\n",
    "- other: Content has no financial crime information OR doesn't fit categories above\n",
    "\n",
    "TASK 3 - SUMMARIZE (summary field):\n",
    "Write a detailed factual summary of financial crime/compliance information found in the content.\n",
    "\n",
    "SCOPE - Include ONLY if explicitly mentioned:\n",
    "- AML/KYC/transaction monitoring deficiencies or failures\n",
    "- Money laundering allegations, investigations, charges, or convictions\n",
    "- Sanctions violations or sanctions-related issues\n",
    "- Fraud, corruption, bribery, or embezzlement\n",
    "- Tax evasion or tax-related crimes\n",
    "- Securities violations or market manipulation\n",
    "- Regulatory fines, penalties, or enforcement actions\n",
    "- Court proceedings, settlements, or legal outcomes\n",
    "- Compliance program failures or remediation efforts\n",
    "\n",
    "RULES:\n",
    "- Use ONLY information explicitly stated in RAW CONTENT - no inference or external knowledge\n",
    "- Always mention \"{entity_name}\" in the summary if the entity appears in the content\n",
    "- Include specific details: amounts, timeframes, jurisdictions, allegations, outcomes, remedial actions\n",
    "- If content has NO financial crime/compliance information, write: \"No financial crime or compliance information is present in the content.\"\n",
    "- Summary can be multiple sentences if needed to capture important details\n",
    "- Do NOT include the publication date in the summary - it goes in the date_published field\n",
    "- RAW CONTENT may include boilerplate (menus/footers/headers), duplicated blocks, and unrelated \n",
    "    text—ignore such noise and extract/classify only substantive financial-crime content.\n",
    "\n",
    "\n",
    "EXAMPLES:\n",
    "\n",
    "Example 1 (detailed fine/settlement):\n",
    "date_published: \"2023-05-15\"\n",
    "claim_type: \"fine\"\n",
    "summary: \"FinCEN fined Danube Logistics €50M for AML violations during 2018-2020 related to inadequate transaction monitoring at Estonian branch operations. The settlement included Danube Logistics admitting to deficiencies in their compliance program. As part of the resolution, Danube Logistics agreed to retain an independent compliance monitor for two years and implement enhanced KYC procedures and high-risk counterparty screening.\"\n",
    "\n",
    "Example 2 (investigation cleared):\n",
    "date_published: \"2024-01-10\"\n",
    "claim_type: \"clearance\"\n",
    "summary: \"DOJ closed an 18-month investigation into Danube Logistics regarding alleged sanctions violations related to transactions with embargoed entities. No charges were filed and Danube Logistics was cleared of all allegations. The investigation examined trade financing activities from 2020-2022.\"\n",
    "\n",
    "Example 3 (no date found):\n",
    "date_published: \"Unknown\"\n",
    "claim_type: \"investigation\"\n",
    "summary: \"Prosecutors are conducting a money-laundering probe into Danube Logistics related to suspicious transactions processed between 2021-2022. The investigation involves alleged failures to file suspicious activity reports and inadequate customer due diligence. No formal charges have been filed yet.\"\n",
    "\n",
    "Example 4 (irrelevant content):\n",
    "date_published: \"Unknown\"\n",
    "claim_type: \"other\"\n",
    "summary: \"No financial crime or compliance information is present in the content.\"\n",
    "\n",
    "Remember: Extract ALL three fields. Focus on factual content from the text only.\n",
    "'''\n",
    "\n",
    "raw_content_1 = ''' Danube Logistics settles AML case with regulator\n",
    "Publisher: Financial Times\n",
    "Byline: FT Staff\n",
    "Date: 2023-05-15\n",
    "\n",
    "The National Financial Authority (NFA) announced that Danube Logistics agreed to pay a\n",
    "€50,000,000 penalty to settle alleged anti-money laundering program deficiencies \n",
    "occurring between 2018 and 2020. According to the NFA’s statement, the settlement resolves \n",
    "findings related to inadequate transaction monitoring and delayed suspicious activity reporting. \n",
    "As part of the settlement, Danube Logistics will retain an independent \n",
    "compliance monitor for two years and complete a remedial program by Q4 2024. \n",
    "The company stated it has overhauled its KYC procedures since 2022 and enhanced screening of high-risk counterparties. \n",
    "\n",
    "No criminal charges were filed, and the NFA described the administrative \n",
    "matter as “resolved via settlement.” Danube Logistics did not admit or deny the findings.\n",
    "\n",
    "'''\n",
    "\n",
    "raw_content_2 = \"\"\"Company town hall transcript\n",
    "\n",
    "Welcome everyone to our Q2 product roadmap review. We’ll focus on UI improvements,\n",
    "faster onboarding, and expanding to two new markets. The session covers customer\n",
    "feedback and hiring plans for engineering and support. No mention of investigations,\n",
    "fines, sanctions, legal cases, or compliance topics.\"\"\"\n",
    "\n",
    "\n",
    "system_message = url_summary_instructions.format( entity_name = \"Danube Logistics\")\n",
    "\n",
    "structured_llm = llm_url_content_summary.with_structured_output( ContentSummary )\n",
    "\n",
    "# populate values  \n",
    "output = structured_llm.invoke([SystemMessage(content=system_message)]+\n",
    "                               [HumanMessage(content=raw_content_2)])\n",
    "\n",
    "# hasattr(journalists,\"journalists\")\n",
    "print( output.model_dump() )\n",
    "print(output.claim_type, output.summary , output.date_published)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a4226",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Support of google search arguments \n",
    "class candidate_names(BaseModel):\n",
    "       comp_names_variation: List[str] = Field(description=\"Different possible variations of company name\")\n",
    "\n",
    "class search_terms_extraction(BaseModel):\n",
    "       or_terms: List[str] = Field(description=\"List of alternative terms and variations for OR search in the specified language\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main state\n",
    "class UnifiedResearchState(TypedDict):\n",
    "    # From UnifiedResearchState\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    search_results: List[LinkCollection]\n",
    "    search_results_raw: List[LinkCollection]\n",
    "    filtered_results: List[LinkCollection]\n",
    "    entity_name: str\n",
    "    expanded_query:str\n",
    "    num_reques_per_lang : int\n",
    "    \n",
    "    # From GenerateAnalystsState\n",
    "    max_journalists: int\n",
    "    journalists: List[Journalist]\n",
    "    hyde_list: List[str]    \n",
    "\n",
    "    # from evidence collection \n",
    "    evidence_claims: List[EvidenceClaim]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95aa02a",
   "metadata": {},
   "source": [
    "#### Supportive tools definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to generate different names of the company\n",
    "llm_dummy = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",  \n",
    "    temperature=0.1,     \n",
    "    max_tokens=100,       \n",
    "    timeout=5,           \n",
    "    max_retries=2   )      \n",
    "\n",
    "entity_name = \"Lukoil\"\n",
    "\n",
    "def extract_name_variations(prompt: str, llm, ln: str = \"en\") -> str:\n",
    "    \"\"\"Generate different variations of how a company name might appear in news articles\"\"\"\n",
    "    \n",
    "    language_mapping = {\n",
    "        'en': 'English',\n",
    "        'ru': 'Russian',\n",
    "        'fr': 'French', \n",
    "        'ro': 'Romanian',\n",
    "        'de': 'German'\n",
    "    }\n",
    "    \n",
    "    full_language_name = language_mapping.get(ln.lower(), 'English')\n",
    "    \n",
    "    template = PromptTemplate(\n",
    "        input_variables=[\"prompt\", \"language\"],\n",
    "        template='''\n",
    "You are a text analysis expert. Extract the company name from this prompt: \"{prompt}\"\n",
    "This name will be used as keywords used for google API, to make it focus only on \n",
    "sources which contain company name.\n",
    "\n",
    "Generate 6-7 possible ways this company name could appear in news articles in {language}.\n",
    "\n",
    "\n",
    "Consider:\n",
    "1. Full official name with legal entity type (PJSC, LLC, Inc., etc.)\n",
    "2. Shortened version without legal entity type\n",
    "3. Common abbreviations or acronyms\n",
    "4. Alternative spellings or transliterations\n",
    "5. How it appears in headlines\n",
    "6. Brand name vs legal name\n",
    "7. Regional variations\n",
    "\n",
    "Return ONLY a JSON array of name variations in {language}.\n",
    "'''\n",
    "    )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(candidate_names)\n",
    "    chain = template | structured_llm\n",
    "    response = chain.invoke({\"prompt\": prompt, \"language\": full_language_name})\n",
    "    \n",
    "    variations_list = response.comp_names_variation\n",
    "    variations_list.append(prompt)\n",
    "    \n",
    "    return \" \".join(variations_list)\n",
    "\n",
    "# Usage:\n",
    "result = extract_name_variations(\"Lukoil money laundering accusations\", llm_dummy, ln=\"en\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define argument for google search \n",
    "\n",
    "def extract_orterms_from_query(search_query: str, llm, ln: str) -> str:\n",
    "    \"\"\"Extract relevant terms from search query for Google orTerms parameter in the specified language\n",
    "    \n",
    "    Args:\n",
    "        search_query (str): The original search query\n",
    "        llm: Language model instance\n",
    "        ln (str): Language code ('en', 'ru', 'fr', 'ro', 'de')\n",
    "        \n",
    "    Returns:\n",
    "        str: Space-separated string of OR terms in the specified language\n",
    "    \"\"\"\n",
    "    \n",
    "    # Language code to full name mapping\n",
    "    language_mapping = {\n",
    "        'en': 'English',\n",
    "        'ru': 'Russian',\n",
    "        'fr': 'French', \n",
    "        'ro': 'Romanian',\n",
    "        'de': 'German'\n",
    "    }\n",
    "    \n",
    "    # Get full language name or default to English\n",
    "    full_language_name = language_mapping.get(ln.lower(), 'English')\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"search_query\", \"language\"],\n",
    "        template='''\n",
    "You are a search optimization expert. Analyze this search query and extract alternative terms that should be used in Google's orTerms parameter.\n",
    "\n",
    "IMPORTANT: Generate ALL terms in {language} language. The response must be entirely in the specified language.\n",
    "\n",
    "Original Query: \"{search_query}\"\n",
    "\n",
    "Extract 6-10 alternative terms covering:\n",
    "1. Company name variations (abbreviations, alternative spellings, transliterations), both in english and  {language}\n",
    "2. Topic/subject variations (synonyms, related terms, technical terms)\n",
    "3. Activity variations (different ways to describe the same concept)\n",
    "\n",
    "For money laundering searches, consider terms like:\n",
    "- Financial crimes, compliance violations, sanctions evasion\n",
    "- AML violations, illicit finance, financial misconduct\n",
    "- Regulatory violations, corruption, fraud\n",
    "\n",
    "For company names, consider:\n",
    "- Official names with/without legal entity types\n",
    "- Common abbreviations, brand names\n",
    "- Alternative spellings or transliterations\n",
    "\n",
    "IMPORTANT: Keep each term SHORT - single words or very short phrases work best for OR logic.\n",
    "CRITICAL: All terms must be in {language} language.\n",
    "\n",
    "Example for English:\n",
    "Query: \"Search for news about Apple Inc related to tax evasion\"\n",
    "orTerms: [\"Apple\", \"AAPL\", \"Apple-Inc\", \"tax-evasion\", \"tax-avoidance\", \"taxation\", \"fiscal\", \"treasury\", \"IRS\", \"revenue\"]\n",
    "\n",
    "Example for Romanian:\n",
    "Query: \"Căutați știri despre Apple Inc legate de evaziunea fiscală\"\n",
    "orTerms: [\"Apple\", \"AAPL\", \"Apple-Inc\", \"evaziune-fiscală\", \"fraudă-fiscală\", \"taxare\", \"fiscal\", \"trezorerie\", \"venituri\", \"impozite\"]\n",
    "\n",
    "Example for Russian:\n",
    "Query: \"Поиск новостей об Apple Inc связанных с уклонением от налогов\"\n",
    "orTerms: [\"Apple\", \"AAPL\", \"Apple-Inc\", \"уклонение-налогов\", \"налоговое-мошенничество\", \"налогообложение\", \"фискальный\", \"казначейство\", \"доходы\", \"налоги\"]\n",
    "\n",
    "Example for French:\n",
    "Query: \"Rechercher des nouvelles sur Apple Inc liées à l'évasion fiscale\"\n",
    "orTerms: [\"Apple\", \"AAPL\", \"Apple-Inc\", \"évasion-fiscale\", \"fraude-fiscale\", \"taxation\", \"fiscal\", \"trésorerie\", \"revenus\", \"impôts\"]\n",
    "\n",
    "Example for German:\n",
    "Query: \"Suchen Sie nach Nachrichten über Apple Inc bezüglich Steuerhinterziehung\"\n",
    "orTerms: [\"Apple\", \"AAPL\", \"Apple-Inc\", \"Steuerhinterziehung\", \"Steuerumgehung\", \"Steuervermeidung\", \"Steuerdelikte\", \"Steuerrecht\", \"Finanzbehörden\", \"Steuerprüfung\", \"Umsätze\", \"Gewinne\", \"Steuern\"]\n",
    "\n",
    "Query: \"{search_query}\"\n",
    "Language: {language}\n",
    "\n",
    "Generate ONLY a list of SHORT alternative terms as a JSON array of strings in {language} language.\n",
    "        '''\n",
    "    )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(search_terms_extraction)\n",
    "    chain = prompt | structured_llm\n",
    "    \n",
    "    response = chain.invoke({\n",
    "        \"search_query\": search_query, \n",
    "        \"language\": full_language_name\n",
    "    })\n",
    "    \n",
    "    # Join the terms with spaces for orTerms parameter\n",
    "    orterms_string = \" \".join(response.or_terms)\n",
    "    \n",
    "    return orterms_string\n",
    "\n",
    "# Usage examples:\n",
    "# English\n",
    "#search_query = \"Search for news and information about TESLA Company company related to money laundering.\"\n",
    "#orterms_for_search = extract_orterms_from_query(search_query, llm_translation_or_terms, \"en\")\n",
    "\n",
    "#print(f\"Original query: {search_query}\")\n",
    "#print(f\"Generated orTerms: {orterms_for_search}\")\n",
    "\n",
    "# Romanian\n",
    "#search_query = \"Căutați știri și informații despre compania PJSC Lukoil Oil Company legate de spălarea banilor.\"\n",
    "#orterms_for_search = extract_orterms_from_query(search_query, llm_translation_or_terms, \"ro\")\n",
    "\n",
    "#print(f\"Original query: {search_query}\")\n",
    "#print(f\"Generated orTerms: {orterms_for_search}\")\n",
    "\n",
    "# Russian\n",
    "#search_query = \"Поиск новостей и информации о компании PJSC Lukoil Oil Company связанных с отмыванием денег.\"\n",
    "#orterms_for_search = extract_orterms_from_query(search_query, llm_translation_or_terms, \"ru\")\n",
    "\n",
    "#print(f\"Original query: {search_query}\")\n",
    "#print(f\"Generated orTerms: {orterms_for_search}\")\n",
    "\n",
    "# French\n",
    "#search_query = \"Rechercher des nouvelles et informations sur la société PJSC Lukoil Oil Company liées au blanchiment d'argent.\"\n",
    "#orterms_for_search = extract_orterms_from_query(search_query, llm_translation_or_terms, \"fr\")\n",
    "\n",
    "#print(f\"Original query: {search_query}\")\n",
    "#print(f\"Generated orTerms: {orterms_for_search}\")\n",
    "\n",
    "# German\n",
    "#search_query = \"Suchen Sie nach Nachrichten und Informationen über die Gesellschaft PJSC Lukoil Oil Company im Zusammenhang mit Geldwäsche.\"\n",
    "#orterms_for_search = extract_orterms_from_query(search_query, llm_translation_or_terms, \"fr\")\n",
    "\n",
    "#print(f\"Original query: {search_query}\")\n",
    "#print(f\"Generated orTerms: {orterms_for_search}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7fad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to translate query \n",
    "## payload will be adjusted to the language but we also need to aligh language of request \n",
    "\n",
    "def translate_query_for_search(query: str, target_lang: str, llm_instance) -> str:\n",
    "    \"\"\"\n",
    "    Translate search query to target language\n",
    "    \n",
    "    Args:\n",
    "        query: Original search query\n",
    "        target_lang: Target language code (en, ru, fr, ro, de)\n",
    "        llm_instance: LLM instance for translation\n",
    "        \n",
    "    Returns:\n",
    "        Translated query string\n",
    "    \"\"\"\n",
    "    language_names = {\n",
    "        \"en\": \"English\",\"ru\": \"Russian\", \"fr\": \"French\",\"ro\": \"Romanian\",\"de\":\"German\"\n",
    "    }\n",
    "\n",
    "    target_language = language_names[target_lang]\n",
    "\n",
    "    translation_prompt = f\"\"\"Translate this search query to {target_language}. \n",
    "                            Keep it concise and search-engine friendly.\n",
    "                            Keep company names in their original form (do not translate company names)\n",
    "                            Use semantically correct terms for fraud, corruption, and reputation-related concepts\n",
    "                            Only return the translated query, nothing else:\n",
    "\n",
    "    Query: {query}\n",
    "\n",
    "    Translation:\"\"\"\n",
    "        \n",
    "    try:\n",
    "        response = llm_instance.invoke(translation_prompt)\n",
    "        translated = response.content.strip() if hasattr(response, 'content') else str(response).strip()\n",
    "        print(f\"Translated '{query}' -> '{translated}' ({target_language})\")\n",
    "\n",
    "        return translated\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}. Using original query.\")\n",
    "        return query\n",
    "    \n",
    "\n",
    "result = translate_query_for_search(\" Information on Money laundering by Lukoil company \" , \"de\" , llm_translation_or_terms)\n",
    "result \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79775f73",
   "metadata": {},
   "source": [
    "####  Google tool definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc777e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### test google api to simulate bad request error \n",
    "# https://developers.google.com/custom-search/v1/reference/rest/v1/cse/list\n",
    "\n",
    "api_key = api_google\n",
    "cse_id = SEARCH_ENGINE_ID\n",
    "\n",
    "service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "\n",
    "result = service.cse().list(\n",
    "            q=\"Lukoil Money Laundering\",\n",
    "            cx=cse_id, # search engine name defined in the console \n",
    "            dateRestrict='y2',  # Agent customizable\n",
    "            start=1,\n",
    "            filter='1', # turn on duplicated filter content \n",
    "            hl='en', # Agent customizable - user interface language\n",
    "            lr='en',  # Agent customizable - language of content             \n",
    "            num=2, # 10 i smax value\n",
    "            safe='off',\n",
    "            orTerms='Lukoil', # if incorrectly specified returned dsearch object may not contain classes\n",
    "            \n",
    "            siteSearch='en.wikipedia.org',  # Agent customizable - Wikipedia language version\n",
    "            siteSearchFilter=\"e\"  # Exclude Wikipedia\n",
    "        ).execute()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search result is stored in items key\n",
    "# it does not contain the publication date of the article/news. \n",
    "if 'items' in result:\n",
    "    for elem in result[\"items\"]:\n",
    "        print(elem.get('displayLink') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d281b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message for llm to create payload \n",
    "system_message_google_search = SystemMessage(content=\"\"\"\n",
    "                                             \n",
    "You are a multi-language search assistant. When asked to search for information, \n",
    "call the google_search tool for EACH of these 5 languages:\n",
    "Make exactly 10 tool calls (one per language)\n",
    "\n",
    "1. **Romanian** (ro):\n",
    "   - hl=\"ro\" (Romanian interface)\n",
    "   - lr=\"lang_ro\" (Romanian content)\n",
    "   - wikipedia_lang=\"ro\" (exclude Romanian Wikipedia)\n",
    "\n",
    "2. **English** (en):\n",
    "   - hl=\"en\" (English interface)  \n",
    "   - lr=\"lang_en\" (English content)\n",
    "   - wikipedia_lang=\"en\" (exclude English Wikipedia)\n",
    "\n",
    "3. **Russian** (ru):\n",
    "   - hl=\"ru\" (Russian interface)\n",
    "   - lr=\"lang_ru\" (Russian content) \n",
    "   - wikipedia_lang=\"ru\" (exclude Russian Wikipedia)\n",
    "\n",
    "4. **French** (fr):\n",
    "   - hl=\"fr\" (French interface)\n",
    "   - lr=\"lang_fr\" (French content)\n",
    "   - wikipedia_lang=\"fr\" (exclude French Wikipedia)\n",
    "                            \n",
    "5. **German** (de):\n",
    "   - hl=\"de\" (German interface)\n",
    "   - lr=\"lang_de\" (German content)\n",
    "   - wikipedia_lang=\"de\" (exclude German Wikipedia)\n",
    "\n",
    "IMPORTANT: Make exactly 10 tool calls (one per language). \n",
    "For each call, use num_results = 10 to retrieve 10 search results per language.\n",
    "Use dateRestrict=\"y3\" (last year) for recent information.\n",
    "\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75290d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common error BadRequestError: Max 20 URLs are allowed.\n",
    "# https://developers.google.com/custom-search/v1/reference/rest/v1/cse/list#try-it \n",
    "\n",
    "## define function for tool schema\n",
    "def google_search(query,  num_results = 5, hl=\"en\", lr=\"lang_en\", dateRestrict=\"y2\", wikipedia_lang=\"en\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Search Google using Custom Search API with configurable parameters.\n",
    "    \n",
    "    This function performs Google searches and returns structured results including titles, URLs, and snippets.\n",
    "    The agent can customize language settings, time restrictions, and Wikipedia language exclusions to optimize search results for specific needs.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    query : str\n",
    "        The search query string to execute\n",
    "    api_key : str  \n",
    "        Google Custom Search API key\n",
    "    cse_id : str\n",
    "        Google Custom Search Engine ID\n",
    "        \n",
    "    Agent Customizable Parameters:\n",
    "    -----------------------------\n",
    "\n",
    "    num_results : int, always included and defined by user\n",
    "    Number of results to return (default: 5, max: 10 per API call), Value must not exceed 10, NOT customisable\n",
    "\n",
    "    hl : str, always included (default: \"en\")\n",
    "        Interface language - controls UI language and affects search quality\n",
    "        Examples: \"en\", \"ru\", \"de\", \"fr\",\"ro\"\n",
    "        \n",
    "    lr : str, always included (default: \"lang_en\") \n",
    "        Content language restriction - filters results by document language\n",
    "        Examples: \"lang_en\", \"lang_ru\", \"lang_de\", \"lang_fr\",\"lang_ro\"\n",
    "        \n",
    "    dateRestrict : str, always included (default: \"d365\")\n",
    "        Time-based filtering for results freshness\n",
    "        Examples: \"d1\" (past day), \"w1\" (past week), \"m1\" (past month), \n",
    "                 \"m3\" (past 3 months), \"m6\" (past 6 months), \"y1\" (past year)\n",
    "    \n",
    "    wikipedia_lang : str, always included (default: \"en\")\n",
    "        Wikipedia language version to exclude from results\n",
    "        Possible values: \"en\" (English), \"ru\" (Russian), \"fr\" (French), \"ro\" (Romanian), \"de\" (German)\n",
    "        Maps to domains: en.wikipedia.org, ru.wikipedia.org, fr.wikipedia.org, ro.wikipedia.org, de.wikipedia.org\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of dictionaries containing search results with keys:\n",
    "        - 'title': Result title\n",
    "        - 'link': Result URL  \n",
    "        - 'snippet': Result description/excerpt\n",
    "        - Additional metadata from Google API\n",
    "        \n",
    "    Example Agent Usage:\n",
    "    -------------------\n",
    "    # For Russian content excluding Russian Wikipedia\n",
    "    results = google_search(query, api_key, cse_id, hl=\"ru\", lr=\"lang_ru\", dateRestrict=\"y3\", wikipedia_lang=\"ru\")\n",
    "    \n",
    "    # For French content excluding French Wikipedia\n",
    "    results = google_search(query, api_key, cse_id, hl=\"fr\", lr=\"lang_fr\", dateRestrict=\"y3\", wikipedia_lang=\"fr\")\n",
    "    \n",
    "    # For Romanian content excluding Romanian Wikipedia\n",
    "    results = google_search(query, api_key, cse_id, hl=\"ro\", lr=\"lang_ro\", dateRestrict=\"y3\", wikipedia_lang=\"ro\")\n",
    "\n",
    "    # For German content excluding German Wikipedia\n",
    "    results = google_search(query, api_key, cse_id, hl=\"de\", lr=\"lang_de\", dateRestrict=\"y3\", wikipedia_lang=\"de\")\n",
    "\n",
    "     # For English content excluding English Wikipedia\n",
    "    results = google_search(query, api_key, cse_id, hl=\"en\", lr=\"lang_en\", dateRestrict=\"y3\", wikipedia_lang=\"en\")\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Executing google_search_payload ...\")\n",
    "\n",
    "    api_key = api_google\n",
    "    cse_id = SEARCH_ENGINE_ID\n",
    "\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "    \n",
    "    # Map language codes to Wikipedia domains\n",
    "    wikipedia_domains = {\n",
    "        \"en\": \"en.wikipedia.org\",\n",
    "        \"ru\": \"ru.wikipedia.org\", \n",
    "        \"fr\": \"fr.wikipedia.org\",\n",
    "        \"ro\": \"ro.wikipedia.org\",\n",
    "        \"de\": \"de.wikipedia.org\"\n",
    "    }\n",
    "    \n",
    "    wikipedia_site = wikipedia_domains.get(wikipedia_lang, \"en.wikipedia.org\")\n",
    "    \n",
    "    ## store search results \n",
    "    all_results = []\n",
    "   \n",
    "    ## query language must be aligned with search parameters\n",
    "    translated_query = translate_query_for_search(query , hl , llm_translation_or_terms)\n",
    "\n",
    "    ## orterms\n",
    "    orterms_for_search = extract_orterms_from_query(translated_query, llm_translation_or_terms, hl )\n",
    "    #orterms_for_search = extract_name_variations(translated_query, llm_translation_or_terms, hl)\n",
    "    print(\"Additional search terms: \" , orterms_for_search)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        result1 = service.cse().list(\n",
    "            q=translated_query,\n",
    "            cx=cse_id, # search engine name defined in the console \n",
    "            dateRestrict=dateRestrict,  # Agent customizable\n",
    "            start=1,\n",
    "            filter='1', # turn on duplicated filter content \n",
    "            hl=hl, # Agent customizable - user interface language\n",
    "            lr=lr,  # Agent customizable - language of content             \n",
    "            num=num_results, \n",
    "            orTerms=orterms_for_search, # each document must contain at least one of the additional terms \n",
    "            safe='off',\n",
    "            siteSearch=wikipedia_site,  # Agent customizable - Wikipedia language version\n",
    "            siteSearchFilter=\"e\"  # Exclude Wikipedia\n",
    "        ).execute()\n",
    "        \n",
    "        if 'items' in result1:\n",
    "                # Extract only relevant information from each result\n",
    "                filtered_items = []\n",
    "                for item in result1['items']:\n",
    "                    essential_data = {\n",
    "                        'query':translated_query,\n",
    "                        'title': item.get('title', ''),\n",
    "                        'link': item.get('link', ''),\n",
    "                        'snippet': item.get('snippet', ''),\n",
    "                        'displayLink': item.get('displayLink', '')\n",
    "                    }\n",
    "                    filtered_items.append(essential_data)\n",
    "\n",
    "                all_results.extend(filtered_items)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting results: {e}\")\n",
    "\n",
    "    print(\"Executing google_search_payload DONE \")    \n",
    "\n",
    "    return all_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5792f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test function \n",
    "tool_google_search = StructuredTool.from_function( google_search, name = \"google_search\" )\n",
    "\n",
    "entity_name = \"Lukoil\"\n",
    "query = f\"{entity_name} money laundering compliance violations investigations\"\n",
    "\n",
    "# join instructions and entity name\n",
    "messages = [ system_message_google_search ,  HumanMessage(content=query) ]\n",
    "\n",
    "## create list of tools, which be called externally with  tool_call['args']\n",
    "tools = [ tool_google_search  ]\n",
    "tools_by_name = {tool.name:tool for tool in tools}\n",
    "\n",
    "# bind first tool to 4o mnodel\n",
    "llm_with_tools = llm_payload.bind_tools(tools)\n",
    "\n",
    "# test tool call without payload \n",
    "#payload = llm_with_tools.invoke( messages )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check payload values\n",
    "#for tool_call in payload.tool_calls:\n",
    "#    print(f\"Tool: {tool_call['name']}\")\n",
    "#    print(f\"ID: {tool_call['id']}\")\n",
    "#    print(f\"Args: {tool_call['args']}\")\n",
    "#    print(\"---\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function  using single payload\n",
    "#tool_call = payload.tool_calls[0]\n",
    "#tool_google_search.invoke( tool_call['args'] )\n",
    "#print(\"##-----------------##\")\n",
    "\n",
    "## Now run through app payloads  \n",
    "#for tool_call in payload.tool_calls: # AI message with payload , last ai message with too l calls\n",
    "#        tool = tools_by_name[tool_call[\"name\"]]\n",
    "#        observations = tool.invoke(tool_call[\"args\"])\n",
    "#        print(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b8ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy unified state\n",
    "\n",
    "dummy_state = UnifiedResearchState(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content = \"Lukoil\" ) ]   \n",
    "    }   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node to create payload for the tool\n",
    "def llm_node(state: UnifiedResearchState):\n",
    "    \"\"\"LLM node that generates tool calls\"\"\"\n",
    "    print(\"Executing llm_node...\")\n",
    "    \n",
    "    # Get the last message from state\n",
    "    entity_name  = state[\"messages\"][-1] # human message\n",
    "    query = f\"{entity_name.content} money laundering criminal activity\"\n",
    "    \n",
    "    ## modified content \n",
    "    human_message_updated = HumanMessage(content=query, id=entity_name.id)\n",
    "    print(\"Updated human message: \" , human_message_updated.content)\n",
    "\n",
    "    ## Replace content of the original human imput \n",
    "    system_message = system_message_google_search\n",
    "\n",
    "    messages = [ system_message ,  human_message_updated ]\n",
    "    \n",
    "    # Call LLM with tools to generate ai message\n",
    "    response = llm_with_tools.invoke( messages )\n",
    "    #print(f\"LLM response: {response}\")\n",
    "    #print(\"State fields \" , state)\n",
    "    \n",
    "    # return all up to last message, replace last human input , company name(for prompts), expanded query for debugging in English\n",
    "    return {\"messages\": state[\"messages\"][:-1] + [human_message_updated, response], \"entity_name\": entity_name.content , \"expanded_query\":query }\n",
    "\n",
    "#print(\"Test Results: \")\n",
    "#dummy_state = llm_node(dummy_state) \n",
    "#print( dummy_state )\n",
    "\n",
    "#for msg in dummy_state.get('messages'):\n",
    "#    if isinstance(msg, AIMessage):\n",
    "#        for msg_tool  in msg.tool_calls:\n",
    "#            print(msg_tool.get(\"args\"))\n",
    "\n",
    "# after payload is populated to AI messages we need to pass args to funcntion\n",
    "# below implemented sequentially "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec706035",
   "metadata": {},
   "outputs": [],
   "source": [
    "## google search tool execution and allocation of seatch results\n",
    "def tool_node_chunk_selection_exec(state: UnifiedResearchState):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "    print(\"Executing tool_node_chunk_selection_exec...\")\n",
    "    \n",
    "    result = []\n",
    "    link_collections = []\n",
    "\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls: # AI message with payload , last ai message with too l calls\n",
    "        tool = tools_by_name[tool_call[\"name\"]] # select tool\n",
    "        observation = tool.invoke(tool_call[\"args\"]) # paste arguments to the tool \n",
    "           \n",
    "        result.append(ToolMessage( # messages are returned by google api not all generated\n",
    "                       content = observation, \n",
    "                       tool_call_id=tool_call[\"id\"] , \n",
    "                       name = tool_call['name']))    \n",
    "        \n",
    "        # Extract LinkCollection data from observation\n",
    "        for item in observation:\n",
    "            if isinstance(item, dict):\n",
    "                # Check if required keys exist\n",
    "                if 'displayLink' in item and 'link' in item:\n",
    "                    link_collection = LinkCollection(\n",
    "                        displayLink=item['displayLink'],\n",
    "                        link=item['link']\n",
    "                    )\n",
    "                    link_collections.append(link_collection)\n",
    "                else:\n",
    "                    # This will only print for items that are missing keys\n",
    "                    available_keys = list(item.keys())\n",
    "                    print(f\"Item missing required keys. Available keys: {available_keys}\")\n",
    "                    print(f\"Item content: {item}\")\n",
    "            else:\n",
    "                print(f\"Item is not a dict, it's: {type(item)}\")\n",
    "        \n",
    "    # we need to populate LinkCollection class and store in  search_results \n",
    "\n",
    "    print(\"Executing tool_node_chunk_selection_exec END\")\n",
    "    return {\"messages\": result , \"search_results\":link_collections }   \n",
    "\n",
    "print(\"Test case: \")\n",
    "#tool_node_chunk_selection_exec(dummy_state)\n",
    "#output = tool_node_chunk_selection_exec(dummy_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72349103",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check classes to store initial link data \n",
    "#for attr in output.get(\"search_results\")[0]:\n",
    "#    print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to display flow using cli\n",
    "\n",
    "def render_mermaid_graph(mermaid_code, output_filename='graph.png', width=700, height=700, cleanup=True):\n",
    "    \"\"\"\n",
    "    Render Mermaid diagram using CLI and display in Jupyter\n",
    "    \"\"\"\n",
    "    # Create temporary mermaid file\n",
    "    temp_mmd = output_filename.replace('.png', '.mmd').replace('.svg', '.mmd').replace('.pdf', '.mmd')\n",
    "    \n",
    "    try:\n",
    "        # Write mermaid code to file\n",
    "        with open(temp_mmd, 'w', encoding='utf-8') as f:\n",
    "            f.write(mermaid_code)\n",
    "        \n",
    "        # Build command based on output format\n",
    "        # Use the Windows .cmd version\n",
    "        cmd = [\n",
    "            'C:\\\\Users\\\\Admin\\\\AppData\\\\Roaming\\\\npm\\\\mmdc.cmd',  # Full path to Windows version\n",
    "            '-i', temp_mmd,\n",
    "            '-o', output_filename,\n",
    "            '-w', str(width),\n",
    "            '-H', str(height)\n",
    "        ]\n",
    "        \n",
    "        # Add size parameters only for PNG/PDF\n",
    "        if output_filename.endswith(('.png', '.pdf')):\n",
    "            cmd.extend(['-w', str(width), '-H', str(height), '--scale', '2'])\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True) # we simulate running command like\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"Graph rendered successfully: {output_filename}\")\n",
    "            try:\n",
    "                display(Image(output_filename))\n",
    "            except:\n",
    "                print(f\"Image saved to {output_filename} but could not display inline\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Mermaid CLI error: {result.stderr}\")\n",
    "            return False\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"Mermaid CLI not found. Install with: npm install -g @mermaid-js/mermaid-cli\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error rendering graph: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        if cleanup and os.path.exists(temp_mmd):\n",
    "            os.remove(temp_mmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b6ba5",
   "metadata": {},
   "source": [
    "#### Prepare Tavily for content extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate summary of extracted content\n",
    "\n",
    "#current approach uses multiple parallel function calls\n",
    "# function process 1 link \n",
    "def generate_url_summary(raw_content: str, llm, entity_name: str, thread_outcomes: dict, url: str):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a focused summary of raw content with emphasis on company reputation \n",
    "    and criminal activity using dedicated LLM.\n",
    "    \n",
    "    Args:\n",
    "        raw_content: Text content to analyze\n",
    "        llm: Language model instance for processing\n",
    "        entity_name: Company name for context\n",
    "        thread_outcomes: used to aggregate outputs of paralles processes\n",
    "        url: used as a key \n",
    "        \n",
    "    Returns:\n",
    "        threadding is applied , no result returned\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Thread for {url} starting...\")\n",
    "\n",
    "    \n",
    "     # Input validation\n",
    "    if not raw_content or not raw_content.strip():\n",
    "        thread_outcomes[url] = \"Error: No content provided for analysis\"\n",
    "        print(f\"No content found for {url} \")\n",
    "        return\n",
    "    \n",
    "    # Truncate content if too long (prevent token limit issues)\n",
    "       # skipped, tavily uses  def first_n_words(text: str, n: int) -> str:\n",
    "    # url_summary_instructions is defined in Main Classes section \n",
    "    # now we need  to populate class with date, summary and intent classification  \n",
    "    #  \n",
    "    try:\n",
    "        system_message = url_summary_instructions.format( entity_name = entity_name )\n",
    "        structured_llm = llm.with_structured_output( ContentSummary )\n",
    "\n",
    "        # populate values  \n",
    "        response = structured_llm.invoke([SystemMessage(content=system_message)]+\n",
    "                                         [HumanMessage(content=raw_content)])\n",
    "        # contains 3 attributes claim_type, summary , date_published\n",
    "        # ex. ContentSummary(claim_type='other', date_published='Unknown', summary='No financial crime or compliance information is present in the content.')\n",
    "        print(response)\n",
    "\n",
    "         # Validate response\n",
    "        if not response or not hasattr(response, 'summary'):\n",
    "            thread_outcomes[url] = \"Error: Invalid response from language model\"\n",
    "            return\n",
    "        \n",
    "        thread_outcomes[url] = response\n",
    "        \n",
    "    except Exception as e:\n",
    "        # More specific error handling\n",
    "        error_msg = f\"Error generating reputation summary: {str(e)}\"\n",
    "        print(error_msg)  # For debugging\n",
    "        thread_outcomes[url] = \"Error: Could not generate reputation summary due to processing issues\"\n",
    "        return \n",
    "\n",
    "\n",
    "# Fixed test call\n",
    "url_to_raw_content = {\n",
    "    # allegation\n",
    "    \"https://news.example.com/article/allegation\": \"\"\"Publisher: Market Watch Europe\n",
    "Date: 2025-01-12\n",
    "Reporters alleged that Danube Logistics facilitated questionable cash-intensive shipments through third-party brokers in 2023. The article cites unnamed sources and notes no official filings or agency statements. Legal status not confirmed; allegations only.\"\"\",\n",
    "\n",
    "    # investigation\n",
    "    \"https://regulator.example.gov/notices/inquiry-2025-02\": \"\"\"Publisher: National Financial Authority\n",
    "Date: 2025-02-05\n",
    "The NFA announced it has opened an investigation into Danube Logistics regarding potential AML/KYC monitoring deficiencies in 2022–2024 cross-border transfers. No fines or charges are imposed at this stage; the probe is ongoing.\"\"\",\n",
    "\n",
    "    # charge\n",
    "    \"https://court.example.org/dockets/indictment-24-771\": \"\"\"Publisher: District Court Bulletin\n",
    "Date: 2024-11-18\n",
    "Prosecutors filed criminal charges against a Danube Logistics regional manager for alleged structuring and false statements. The indictment specifies three counts; the company itself is not charged. Arraignment is scheduled next month.\"\"\",\n",
    "\n",
    "    # conviction\n",
    "    \"https://court.example.org/verdicts/2025-03-14\": \"\"\"Publisher: District Court Bulletin\n",
    "Date: 2025-03-14\n",
    "A jury convicted a former Danube Logistics contractor on two counts of money laundering tied to 2021 transactions. The order notes no finding against Danube Logistics as a corporate entity. Sentencing set for May.\"\"\",\n",
    "\n",
    "    # plea\n",
    "    \"https://justice.example.gov/releases/plea-agreement-2024-10-02\": \"\"\"Publisher: Ministry of Justice\n",
    "Date: 2024-10-02\n",
    "A former operations lead at Danube Logistics entered a guilty plea to one count of failing to file required reports. The plea agreement includes cooperation and a recommended fine; the filing does not charge the company.\"\"\",\n",
    "\n",
    "    # fine\n",
    "    \"https://nfa.example.gov/enforcement/actions/2025-04-20\": \"\"\"Publisher: National Financial Authority\n",
    "Date: 2025-04-20\n",
    "The NFA fined Danube Logistics €12,500,000 for AML program deficiencies related to delayed suspicious activity reporting in 2022. The civil penalty order cites inadequate alert tuning and training gaps.\"\"\",\n",
    "\n",
    "    # settlement\n",
    "    \"https://newswire.example.com/releases/settlement-announce\": \"\"\"Publisher: Financial Times\n",
    "Date: 2023-05-15\n",
    "Danube Logistics reached a settlement resolving an administrative AML matter with the NFA, agreeing to pay €50,000,000 and retain an independent monitor for two years. The company did not admit or deny the findings; no criminal charges were filed.\"\"\",\n",
    "\n",
    "    # clearance\n",
    "    \"https://regulator.example.gov/notices/closure-2025-06\": \"\"\"Publisher: National Financial Authority\n",
    "Date: 2025-06-09\n",
    "Following review, the NFA closed its investigation into Danube Logistics with no enforcement action. The notice states that evidence was insufficient to support alleged violations and the matter is dismissed.\"\"\",\n",
    "\n",
    "    # sanction_listing\n",
    "    \"https://sanctions.example.gov/updates/listing-2024-09-28\": \"\"\"Publisher: Ministry of Finance — Sanctions Directorate\n",
    "Date: 2024-09-28\n",
    "The Sanctions Directorate listed Danube Logistics Trading FZE on the national sanctions list for involvement in evasion schemes. The designation imposes asset freezes and prohibits transactions with listed parties.\"\"\",\n",
    "\n",
    "    # other (irrelevant/neutral ops update)\n",
    "    \"https://blog.example.org/posts/ops-expansion\": \"\"\"Publisher: Logistics Today\n",
    "Date: 2025-03-02\n",
    "Danube Logistics announced a 40,000 m² distribution center with automated sortation and cold-chain capacity, plus 120 new jobs. The post discusses sustainability features and scheduling software. No legal or compliance topics are mentioned.\"\"\",\n",
    "\n",
    "    \"https://blog.example.org/DUMMY\" : 'weather in scotland'\n",
    "}\n",
    "\n",
    "\n",
    "thread_outcomes = {}\n",
    "\n",
    "# now trreading\n",
    "threads = []\n",
    "entity_name = \"Danube Logistics\" \n",
    "\n",
    "for url, raw_content in url_to_raw_content.items():\n",
    "    t = threading.Thread( \n",
    "        target = generate_url_summary ,\n",
    "        args = ( raw_content, llm_url_content_summary, entity_name, thread_outcomes, url )\n",
    "     )\n",
    "    threads.append(t)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start() \n",
    "\n",
    "for thread in threads:\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thread_outcomes\n",
    "#thread_outcomes['https://regulator.example.gov/notices/closure-2025-06'].claim_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d44566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test extraction \n",
    "tavily_client = TavilyClient(api_key=tavily_api)\n",
    "url = 'https://www.ebrd.com/home/news-and-events/news/2023/ebrd-will-appeal-imposed-external-administration-of-assets-of-moldovas-danube-logistics-srl.html'\n",
    "output = tavily_client.extract(urls=url, extract_depth='advanced', format = 'markdown') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output\n",
    "# single large string which includes the whole page, footers, cookies, article body, header, navigation\n",
    "# data requires post cleaning , keep for later , add to summarisation promot that \n",
    "# content can contain irrelecant pieces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client once at module level\n",
    "# https://docs.tavily.com/documentation/api-reference/endpoint/extract\n",
    "\n",
    "#  avily API has a limit of 20 URLs per extraction request\n",
    "# we can face error bad requiest max 20 is allowed\n",
    "\n",
    "# function will run inside the node, tool is not generated \n",
    "# as application is strainghforward \n",
    "\n",
    "def tavily_content_extractor(\n",
    "    dummy_state: List[LinkCollection], # will be populated with new data from ClassSummary   \n",
    "    extract_depth: str = \"advanced\", # advanced  basic\n",
    "    include_raw_content: bool = True,\n",
    "    entity_name:str = \"\"\n",
    "\n",
    ") -> List[LinkCollection]:\n",
    "    \n",
    "    print(\"Executing content extraction...\")\n",
    "\n",
    "    # store urls values\n",
    "    urls = [link.link for link in dummy_state] # link_collection.link\n",
    "    displayLinks = [link.displayLink for link in dummy_state]\n",
    "    ## map url and displayLink based on link_collection.displayLink\n",
    "    url_to_displayLink = {url: displayLink for url, displayLink in zip(urls, displayLinks)}\n",
    "    \n",
    "    ## extract all urls in batches, tavily limits to 20 requests\n",
    "    BATCH_SIZE = 20 \n",
    "    url_to_raw_content = {} # need to store \"url\" and \"raw_content\"\n",
    "\n",
    "    def first_n_words(text: str, n: int) -> str:\n",
    "        return \" \".join(text.split()[:n])\n",
    "\n",
    "    for i in range(0, len(urls), BATCH_SIZE ):\n",
    "        batch_urls = urls[i: ( i + BATCH_SIZE ) ]\n",
    "        print(f\"Processing batch {i//BATCH_SIZE + 1}: {len(batch_urls)} URLs\")\n",
    "\n",
    "        try: \n",
    "            response = tavily_client.extract(urls=batch_urls, extract_depth=extract_depth, format = 'markdown')     \n",
    "\n",
    "            # Map URLs to content from this batch\n",
    "            for item in response.get('results', []):\n",
    "                url = item.get(\"url\", \"\")\n",
    "                content = item.get(\"raw_content\", \"\")\n",
    "                url_to_raw_content[url] = first_n_words(content , 5000) \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting batch: {e}\")\n",
    "            # Continue with empty content for failed URLs\n",
    "            for url in batch_urls:\n",
    "                if url not in url_to_raw_content:\n",
    "                    url_to_raw_content[url] = \"\"    \n",
    "\n",
    "    ## We need to keep only non empty content which contains name of the company                    \n",
    "    # url_to_raw_content to url_to_raw_content_filtered\n",
    "    parts, name_re = generate_name_regex(entity_name, llm_names_variation)\n",
    "    print(parts)  # Optional: see \"Original | Russian\"\n",
    "    url_to_raw_content_filtered = {url:content for url,content in url_to_raw_content.items() if name_re.search(content)}\n",
    "    \n",
    "\n",
    "    # Create new LinkCollection objects with matched raw_content\n",
    "    updated_collections = []\n",
    "    thread_outcomes = {}\n",
    "    threads = []\n",
    "    \n",
    "    print(f\"Entity name: {entity_name} \")\n",
    "    for url, raw_content in url_to_raw_content_filtered.items():\n",
    "        t = threading.Thread( \n",
    "            target = generate_url_summary ,\n",
    "            args = ( raw_content, llm_url_content_summary, entity_name, thread_outcomes, url )\n",
    "        )\n",
    "        threads.append(t)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.start() \n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    # now thread_outcomes is populated with pairs url, summary  \n",
    "\n",
    "    # debug \n",
    "    print(f\"Total number of links by google search: {len(urls)}\")\n",
    "    print(f\"URLs in url_to_raw_content: {len(url_to_raw_content)}\")\n",
    "    print(f\"URLs in url_to_raw_content_filtered: {len(url_to_raw_content_filtered)}\")\n",
    "    print(f\"URLs in thread_outcomes: {len(thread_outcomes)}\")\n",
    "    print(f\"URLs in url_to_displayLink: {len(url_to_displayLink)}\")  \n",
    "\n",
    "    # now unpack the dictionary which contains 3 attributes which we need to add to Link Collection\n",
    "    # claim_type='other' date_published='Unknown' summary='No financial crime or compliance information is present in the content.'\n",
    "    for url in thread_outcomes:       \n",
    "        updated_collection = LinkCollection(\n",
    "            displayLink=url_to_displayLink[url],\n",
    "            link=url,\n",
    "            raw_content=url_to_raw_content[url],\n",
    "            summary=thread_outcomes[url].summary, \n",
    "            claim_type=thread_outcomes[url].claim_type, \n",
    "            date_published=thread_outcomes[url].date_published\n",
    "        )\n",
    "        \n",
    "        updated_collections.append(updated_collection)\n",
    "\n",
    "    print(\"Executing content extraction Done\")\n",
    "\n",
    "    return updated_collections\n",
    "\n",
    "# Test \n",
    "#dummy = tavily_content_extractor(dummy_state=results[\"search_results\"],  entity_name= results[\"entity_name\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714dd770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function above will not be implemented as tool \n",
    "# we will update search_results component for each LinkCollection\n",
    "\n",
    "def extract_content(state: UnifiedResearchState) -> UnifiedResearchState :\n",
    "    \"\"\"Node function to extract content from URLs in search results\"\"\"\n",
    "    \n",
    "    print(\"Executing extract_content...\")\n",
    "    \n",
    "    dummy_state = state[\"search_results\"].copy()\n",
    "    updated_search_result = tavily_content_extractor(dummy_state=dummy_state , entity_name = state[\"entity_name\"])\n",
    "    \n",
    "    print(\"Extract_content completed Done\")\n",
    "\n",
    "    return {\"search_results\": updated_search_result, \"search_results_raw\":dummy_state} # replace the searchresult field\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a76743",
   "metadata": {},
   "source": [
    "#### Unite Research and HyDe agent into 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9cbb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## input comes from expanded query formed after llm node\n",
    "## now define nodes \n",
    "\n",
    "def create_journalists( state:UnifiedResearchState  ) :\n",
    "     \n",
    "     \"\"\" create journalist \"\"\" \n",
    "\n",
    "     print(\"Executing create_journalists ... \")\n",
    "\n",
    "      # prompts arguments\n",
    "     crime_topic=state['expanded_query']\n",
    "     max_journalists=state['max_journalists']\n",
    "     \n",
    "     # llm to generate persona \n",
    "     structured_llm = llm_class_generation.with_structured_output( HydePerspectives )\n",
    "\n",
    "     system_message = journalist_instructions.format( crime_topic = crime_topic , \n",
    "                                                      max_journalists= max_journalists\n",
    "                                                     )\n",
    "     print( \"System Instructions: \" , system_message[:100])\n",
    "     \n",
    "     # populate values  \n",
    "     journalists = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=\"Generate the set of journalists according to instructions\")])\n",
    "\n",
    "     print(\"Executing create_journalists Done \")\n",
    "\n",
    "     return { \"journalists\": journalists.journalists }\n",
    "\n",
    "\n",
    "\n",
    "## function to write article \n",
    "def generate_hyde_document(state:UnifiedResearchState): \n",
    "\n",
    "    \"\"\"Generate Hyde articles using journalist personas\"\"\"\n",
    "\n",
    "    print(\"Executing generate_hyde_document ... \")\n",
    "\n",
    "    article_template = \"\"\"You are a journalist with the profile below. Write a short, hypothetical article for retrieval (HyDE). :\n",
    "            \n",
    "            Company name (repeat it several times): {entity_name}\n",
    "            Expertise: {expertise}\n",
    "            Perspective: {perspective}\n",
    "            Style: {style}\n",
    "            Topic to cover: {crime_topic}\n",
    "\n",
    "            Constraints:\n",
    "            - 350 - 400 words, plain text (no markdown).\n",
    "            - Include AML/KYC lexicon where natural: anti-money laundering (AML), know-your-customer (KYC), transaction monitoring,\n",
    "              suspicious activity reports (SARs), correspondent banking, beneficial ownership, PEP, sanctions, consent order, settlement, probe.\n",
    "            - Keep a neutral, reportorial tone; this is hypothetical for search, not a claim.\n",
    "            - If topic lacks dates/amounts, use vague ranges. Do not fabricate concrete numbers.\n",
    "\n",
    "\n",
    "            Structure to follow (inline, no headings):\n",
    "            - Headline that includes \"{entity_name}\".\n",
    "            - One-sentence dek summarizing the angle.\n",
    "            - Lede paragraph naming {entity_name} and the jurisdiction/sector if implied by the topic.\n",
    "            - One paragraph with AML/KYC process vocabulary and typical risk indicators.\n",
    "            - One paragraph on regulatory/enforcement posture (investigation/settlement/fine allegations as applicable).\n",
    "            - Closing sentence that restates {entity_name} and the core issue.\n",
    "\n",
    "            Write the article now.\n",
    "\n",
    "\"\"\"\n",
    "            \n",
    "    hyde_list = []\n",
    "\n",
    "    print(\"Unpacking journalists classes\")\n",
    "\n",
    "    ## unpack values in journalists field\n",
    "    journalists =  [ state[\"journalists\"] ] \n",
    "\n",
    "    for elem in state['journalists']:\n",
    "        prompt = article_template.format(\n",
    "            expertise=elem.expertise,\n",
    "            perspective=elem.perspective, \n",
    "            style=elem.style,\n",
    "            crime_topic=state[\"expanded_query\"],\n",
    "            entity_name = state['entity_name']\n",
    "        )\n",
    "\n",
    "        print(\"Prompt to create Article: \", prompt[:400])\n",
    "        article = llm_hyde_generation.invoke([HumanMessage(content=prompt)])\n",
    "        hyde_list.append(article.content)\n",
    "\n",
    "    print(\"Executing generate_hyde_document Done \")    \n",
    "\n",
    "    return {\"hyde_list\": hyde_list}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e23573",
   "metadata": {},
   "source": [
    "#### Prepare module for cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1cb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ok test comparison algo , each article is compared against\n",
    "## HeDe docs\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# we compare 1 article agains max_journalist , the format is ( n_row , n_journalists ) \n",
    "\n",
    "text_samples = [\n",
    "    \"The financial institution faces significant regulatory compliance challenges and potential money laundering violations that could impact its banking partnerships.\",\n",
    "    \n",
    "    \"Recent investigations reveal operational risk factors including inadequate anti-money laundering controls and suspicious transaction monitoring failures.\",\n",
    "    \n",
    "    \"Market analysts express concerns about reputational damage from ongoing legal proceedings and regulatory scrutiny affecting stakeholder confidence.\"\n",
    "]\n",
    "\n",
    "url_content = text_samples[1]\n",
    "\n",
    "## form embedding of original \n",
    "\n",
    "vector_url_content = np.array( embedding_cross_lang.embed_query(url_content) )\n",
    "vector_url_content = vector_url_content.reshape(1,-1)\n",
    "print(vector_url_content.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8e03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function will be iteravely applied over each content \n",
    "\n",
    "def check_content_similarity(\n",
    "    search_results: List[LinkCollection], \n",
    "    hyde_list: npt.NDArray[np.float64]\n",
    ") -> List[LinkCollection]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Check if URL content has high similarity to any Hyde document\n",
    "    \n",
    "    Args:\n",
    "        search_results: List of LinkCollection objects with raw_content\n",
    "        hyde_list: numpy array of shape (n, 1536) containing Hyde embeddings\n",
    "    \n",
    "    Returns:\n",
    "        float: Maximum cosine similarity score rounded to hundredth (2 decimal places)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Store max similarity score for each URL\n",
    "    updated_collections = []  # stroe new values for the collection, later replace, solution is redundant\n",
    "    for link in search_results:\n",
    "\n",
    "        url_content = link.raw_content\n",
    "        \n",
    "        # Embed URL content, cap is 300 000 tokens, 1 token is aproximately 4 characters, Embedding error: Error code: 400 - {'error': {'message': 'Requested 307281 tokens, max 300000 tokens per request', 't\n",
    "        try:\n",
    "           url_content_embed = np.array(\n",
    "               embedding_cross_lang.embed_query(url_content[:800000])\n",
    "           ).reshape(1, -1)\n",
    "        except Exception as e:\n",
    "           print(f\"Embedding error: {str(e)[:100]}\")\n",
    "           url_content_embed = np.zeros((1, 3072))  # Default embedding for text-embedding-3-large\n",
    "        \n",
    "        # calculate similarity scores against all Hyde embeddings\n",
    "        similarity_scores = cosine_similarity(url_content_embed, hyde_list)\n",
    "        \n",
    "        # Find and store max similarity for this URL\n",
    "        max_score = round(float(np.max(similarity_scores)), 2)\n",
    "        \n",
    "       \n",
    "        # update the state values , fix later \n",
    "        updated_collection = LinkCollection(\n",
    "            displayLink=link.displayLink,\n",
    "            link=link.link,\n",
    "            raw_content=link.raw_content,\n",
    "            summary=link.summary,\n",
    "            claim_type=link.claim_type, \n",
    "            date_published=link.date_published,\n",
    "            hyde_score=max_score\n",
    "        )\n",
    "        \n",
    "        updated_collections.append(updated_collection)\n",
    "    \n",
    "    return updated_collections\n",
    "\n",
    "# Usage:\n",
    "#results[\"search_results\"] = check_content_similarity(\n",
    "#    results[\"search_results\"], \n",
    "#    hyde_content_list_embed\n",
    "#)\n",
    "\n",
    "# Tools are for external API, actions which requires LLM to decide parameters , sityation whcih required dynamic parameters\n",
    "# Here we process data which already in a state, no external api, state modification, sequential processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7587e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node to update  state[\"search_results\"] and keep only relevant material for summary \n",
    "\n",
    "def filter_relevant_content(state: UnifiedResearchState) -> UnifiedResearchState:\n",
    "    \"\"\"Filter and sort search results by HyDE relevance score\"\"\"\n",
    "    \n",
    "    print(\"Executing filter_relevant_content...\")\n",
    "    \n",
    "    RELEVANCE_THRESHOLD = 0.0  # Configurable\n",
    "    TOP_K = 30  # Maximum articles to keep\n",
    "    \n",
    "    # Filter items with scores\n",
    "    scored_items = [\n",
    "        link for link in state[\"search_results\"]\n",
    "        if link.hyde_score is not None\n",
    "    ]\n",
    "    \n",
    "    # Sort by score (descending)\n",
    "    sorted_items = sorted(\n",
    "        scored_items, \n",
    "        key=lambda x: x.hyde_score, \n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    ## now genetate variation names \n",
    "    parts, name_re = generate_name_regex(state['entity_name'], llm_names_variation)\n",
    "    print(parts)  # Optional: see \"Original | Russian\"\n",
    "\n",
    "    def in_summary(item) -> bool:\n",
    "        s = getattr(item, \"summary\", \"\") or \"\"\n",
    "        return bool(name_re.search(s))\n",
    "    \n",
    "   #  name filter first ---\n",
    "    name_filtered = [item for item in sorted_items if in_summary(item)]\n",
    "    print(f\"Total articles: {len(state['search_results'])}\")\n",
    "    print(f\"Articles with scores: {len(scored_items)}\")\n",
    "    print(f\"Name-matched (summary contains company name): {len(name_filtered)}\")\n",
    "    \n",
    "   # threshold filtering\n",
    "    threshold_filtered = [it for it in name_filtered if it.hyde_score >= RELEVANCE_THRESHOLD]\n",
    "    filtered = threshold_filtered[:TOP_K]\n",
    "    print(f\"Above threshold ({RELEVANCE_THRESHOLD}): {len(threshold_filtered)}\")\n",
    "    print(f\"Returned (TOP_K={TOP_K}): {len(filtered)}\")\n",
    "\n",
    "    if filtered:\n",
    "        scores = [item.hyde_score for item in filtered]\n",
    "        print(f\"Score range: {min(scores):.2f} - {max(scores):.2f}\")\n",
    "        print(f\"Top 5 sources example: {[item.displayLink[:30] for item in filtered[:5]]}\")\n",
    "    else:\n",
    "        print(\"WARNING: No articles passed relevance threshold!\")\n",
    "    \n",
    "    print(\"Executing filter_relevant_content Done\")\n",
    "    \n",
    "    return {\"filtered_results\": filtered}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c058482",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now prepare function to integrate into main flow \n",
    "\n",
    "# with cosine we should distingusin \n",
    "#company accused in money laundering, mentioned in article about laundering\n",
    "# denying accusations, complying with anti money policy\n",
    "\n",
    "def assign_score_vs_hyde(state: UnifiedResearchState) -> UnifiedResearchState :\n",
    "    \"\"\"Node function to estimate similarity score agains HyDe documents\"\"\"\n",
    "    \n",
    "    print(\"Executing assign_score_vs_hyde...\")\n",
    "\n",
    "    ## prepare HydeEmbeddings \n",
    "    hyde_content_list = state.get(\"hyde_list\", None)\n",
    "    # hyde_content_list_embed = np.vstack([  np.array( embedding_cross_lang.embed_query(article) ).reshape(1,-1) for article in hyde_content_list ])\n",
    "\n",
    "    hyde_embeddings = embedding_cross_lang.embed_documents(hyde_content_list)\n",
    "    hyde_content_list_embed = np.array(hyde_embeddings)\n",
    "    \n",
    "    ## prepare input for score estimation\n",
    "    dummy_state = state[\"search_results\"].copy()\n",
    "    updated_search_result = check_content_similarity(search_results=dummy_state , hyde_list = hyde_content_list_embed )\n",
    "    \n",
    "    print(\" Executing assign_score_vs_hyde  Done\")\n",
    "\n",
    "    return {\"search_results\": updated_search_result} # replace the searchresult field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b0d49c",
   "metadata": {},
   "source": [
    "#### Evidence Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa14340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need verifiation that final assessment clains are based on the evidence \n",
    "# collected as summaries \n",
    "# We need to emplly evidence therefore add modules to trace the process\n",
    "\n",
    "# Eventually, evidences must be collected into reusable sharable format \n",
    "# It should help to avoid hallusination and back up arguments with evidences \n",
    "\n",
    "# we require consistent deduplication, inproved output structure with more discinplined extraction, lower hallucination\n",
    "# LengthFinishReasonError: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=4000, prompt_tokens=3174, total_tokens=7174,\n",
    "\n",
    "\n",
    "## test the class \n",
    "\n",
    "def extract_evidence_claims(state:UnifiedResearchState) -> Dict: \n",
    "    \n",
    "    \"\"\"Extract claims from summaries and consolidate duplicate claims across sources\"\"\"\n",
    "    \n",
    "    print(\"Extracting and consolidating evidence claims...\")\n",
    "\n",
    "    # prepare summaries \n",
    "    summaries_data = [] # each element is dictionary wish summary data \n",
    "\n",
    "    for link in state[\"filtered_results\"]: \n",
    "        if link.summary.strip(): \n",
    "            summaries_data.append(\n",
    "                {\n",
    "                \"url\": link.link,\n",
    "                \"source\": link.displayLink,\n",
    "                \"summary\": link.summary, # contains date\n",
    "                \"claim_type\": link.claim_type,\n",
    "                \"date_published\":link.date_published,\n",
    "                \"hyde_score\": link.hyde_score\n",
    "                }\n",
    "            )\n",
    "\n",
    "    print(\"Data from which to consolidate evidences: \" , json.dumps(summaries_data, indent=2))\n",
    "\n",
    "    extraction_prompt = f\"\"\"\n",
    "Consolidate financial-crime/compliance claims about {state[\"entity_name\"]} from the PRE-CLASSIFIED summaries below.\n",
    "\n",
    "IMPORTANT\n",
    "- Do NOT re-classify. Use each item's `claim_type` as ground truth.\n",
    "- Do NOT invent facts or fields. Use only what is present in the summaries.\n",
    "- Return ONLY the structured object matching `ClaimsFromSummaries` (no extra text).\n",
    "\n",
    "INPUT (per item): url, source, summary, claim_type, date_published, hyde_score\n",
    "\n",
    "SCOPE & FILTERS\n",
    "- Include ONLY items about {state[\"entity_name\"]}. If an item focuses on another company, skip it.\n",
    "- If an affiliate/subsidiary is mentioned, include only if the summary explicitly ties it to {state[\"entity_name\"]} (ownership/control/parent–subsidiary stated). Otherwise skip.\n",
    "- Ignore items that explicitly say there is no information about {state[\"entity_name\"]}.\n",
    "- RAW CONTENT may include boilerplate or unrelated text—ignore noise and use only substantive financial-crime details.\n",
    "\n",
    "DEFINITION — CLUSTER\n",
    "- A **cluster** is a set of items that describe the **same underlying event** and share the same `claim_type`.\n",
    "- “Underlying event” means a single discrete action/outcome (e.g., one fine order, one settlement agreement, one charge/indictment, one conviction/plea, one sanctions listing, one clearance/closure, one investigation opening) concerning {state[\"entity_name\"]}.\n",
    "- Press updates or multiple articles about the **same** order/filing/decision belong to the **same cluster**.\n",
    "- If there is a **material difference** (e.g., different regulator/agency, different amount/currency, different case number or court, clearly different event dates), treat as **separate clusters** even if wording is similar.\n",
    "- Each **cluster maps to exactly one `EvidenceClaim`** (one cluster ⇒ one claim).\n",
    "\n",
    "CONSOLIDATION (NO RE-CLASSIFICATION)\n",
    "1) Form clusters using semantic overlap in:\n",
    "   - regulator/agency/court names\n",
    "   - action (fine/settlement/charge/plea/conviction/investigation/allegation/clearance/sanction_listing)\n",
    "   - amounts & currency (treat “€1.5B” ≈ “€1,500,000,000”)\n",
    "   - timeframe or event date window\n",
    "   - jurisdiction/country/court\n",
    "   When uncertain, prefer merging items with higher `hyde_score`; if still unsure, keep separate claims.\n",
    "\n",
    "2) For each cluster, output ONE `EvidenceClaim`:\n",
    "   - `claim_text`: One precise sentence for {state[\"entity_name\"]} capturing shared details (amounts, agency, timeframe, jurisdiction). If sources conflict on a detail, omit that detail rather than guessing.\n",
    "   - `claim_type`: COPY from the clustered items (do not change).\n",
    "   - `supporting_urls`: ALL unique URLs from the cluster. Deduplicate. Order by descending `hyde_score`; if scores tie or are missing, preserve first appearance.\n",
    "   - `date_publish`: choose in this order:\n",
    "       a) A clear event date in the summaries (YYYY-MM-DD).\n",
    "       b) Else the most recent non-\"Unknown\" publication date among the clustered items.\n",
    "       c) Else \"Unknown\".\n",
    "\n",
    "3) If items refer to the same matter but have DIFFERENT `claim_type` (e.g., investigation → settlement → clearance), output SEPARATE claims (one per type).\n",
    "\n",
    "FORMAT RULES\n",
    "- `date_publish` must be \"YYYY-MM-DD\" or \"Unknown\".\n",
    "- If no valid claims remain after filtering, return `evidence_claims: []`.\n",
    "- Sort `evidence_claims` by `date_publish` ascending; place \"Unknown\" dates last.\n",
    "\n",
    "Summaries to analyze:\n",
    "{json.dumps(summaries_data, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    # debug\n",
    "    #print(json.dumps(summaries_data, indent=2))\n",
    "\n",
    "\n",
    "    structured_llm = llm_agg_summaries.with_structured_output( ClaimsFromSummaries )\n",
    "\n",
    "    response = structured_llm.invoke([\n",
    "        SystemMessage(content= f\"\"\"\n",
    "                You are a forensic Financial Crimes Analysts of company {state[\"entity_name\"]}\n",
    "\n",
    "                Follow these constraints:\n",
    "                - Use only information contained in the user message; do not add outside knowledge.\n",
    "                - Do not guess missing details (dates, amounts, agencies).\n",
    "                - Produce consolidated, non-duplicative claims and include provenance (supporting URLs).\n",
    "                - Choose exactly one claim_type per claim, using the schema provided by the user.\n",
    "                - If nothing qualifies under these constraints, return an empty list.\n",
    "                \"\"\" )\n",
    "                ,      \n",
    "\n",
    "        HumanMessage(content=extraction_prompt)\n",
    "        \n",
    "    ])\n",
    "\n",
    "    print(f\"Extracted {len(response.evidence_claims)} unique claims from {len(summaries_data)} summaries\")\n",
    "    # json dums return string which is applied to promot via f syntax\n",
    "\n",
    "    print(response.evidence_claims)\n",
    "    return {\"evidence_claims\" : response.evidence_claims}\n",
    "\n",
    "#buff = extract_evidence_claims(results)  # tested \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust summarisation node \n",
    "\n",
    "def generate_risk_assessment(state: UnifiedResearchState):\n",
    "    \"\"\"Generate comprehensive AML risk assessment from evidence claims\"\"\"\n",
    "    \n",
    "    print(\"Executing generate_risk_assessment...\")\n",
    "    \n",
    "    print(\"State keys\" , state.keys())\n",
    "    types = {c.claim_type for c in state[\"evidence_claims\"]}\n",
    "    claims_by_type = {t: [] for t in types}\n",
    "\n",
    "    print(\"Claim types:\", sorted(types)) # myst be fine investigation, allegation, clearance, settlement\n",
    "    \n",
    "    ## now prepare input for final summarisation prompt \n",
    "    print(\"Iterate through claim cases: \")\n",
    "    for claim in state[\"evidence_claims\"]:\n",
    "        claims_by_type[claim.claim_type].append({\n",
    "            \"text\": claim.claim_text,\n",
    "            \"sources\": len(claim.supporting_urls),\n",
    "            \"date_publish\":claim.date_publish\n",
    "        })\n",
    "    \n",
    "    entity_name = state[\"entity_name\"]\n",
    "    \n",
    "    system_message = SystemMessage(content=f\"\"\"\n",
    "    You are a senior AML compliance officer conducting risk assessment for {entity_name}.\n",
    "    \n",
    "    Analyze the evidence to determine banking partnership viability.\n",
    "    \n",
    "    KEY ASSESSMENT CRITERIA:\n",
    "    \n",
    "    1. VIOLATION SEVERITY\n",
    "    - Calculate total fines from the evidence (don't hardcode)\n",
    "    - Identify the scale of violations (amounts involved vs fines paid)\n",
    "    - Determine if violations were systemic or isolated\n",
    "    \n",
    "    2. CURRENT RISK STATUS\n",
    "    - Count active investigations (ongoing = unresolved risk)\n",
    "    - Identify investigating authorities \n",
    "    - Assess geographic spread (multiple jurisdictions = higher risk)\n",
    "    - Evaluate timeline and provide quote with date in ISO 8601 format (recent violations = weak current controls)\n",
    "    \n",
    "    3. CONTROL ENVIRONMENT\n",
    "    - Evaluate settlement efforts (genuine improvement vs PR)\n",
    "    - Check for leadership accountability (executives resigned?)\n",
    "    - Assess system improvements (new AML systems, training?)\n",
    "    \n",
    "    4. PATTERN RECOGNITION\n",
    "    - Multiple fines for similar issues = poor compliance culture\n",
    "    - Repeated violations across years = systemic failure\n",
    "    - Mix of old violations + strong settlement = possible reform\n",
    "    \n",
    "    DECISION FRAMEWORK:\n",
    "    \n",
    "    AVOID PARTNERSHIP if:\n",
    "    - Criminal investigations ongoing\n",
    "    - Multiple violations without meaningful settlement\n",
    "    - Pattern of violations continuing to present\n",
    "    - Total fines exceed €1 billion with no improvement\n",
    "    \n",
    "    ENHANCED DUE DILIGENCE if:\n",
    "    - Significant past violations but settled\n",
    "    - Active settlement program with evidence\n",
    "    - Civil investigations ongoing (not criminal)\n",
    "    - Mix of violations and clearances\n",
    "    \n",
    "    \n",
    "    REQUIRED OUTPUT:\n",
    "    1. EXECUTIVE SUMMARY: Core issues and total financial impact (calculate from evidence)\n",
    "    2. VIOLATION ANALYSIS: What they did wrong and when\n",
    "    3. CURRENT STATUS: What's resolved vs ongoing\n",
    "    4. TRAJECTORY: Getting better or worse? (compare dates)\n",
    "    5. RISK RATING: HIGH/MEDIUM/LOW with specific justification\n",
    "    6. PARTNERSHIP RECOMMENDATION: Your decision with conditions\n",
    "    \n",
    "    Be specific about amounts, dates, and authorities involved.\n",
    "\n",
    "    Each Summary must end with structurem here is example, Keep same criteria but\n",
    "    Content for Status/Details can vary\n",
    "\n",
    "    **Summary Table**\n",
    "\n",
    "| Criteria                | Status/Details                                           |\n",
    "|-------------------------|---------------------------------------------------------|\n",
    "| Total Fines Paid        | €0                                                      |\n",
    "| Most Serious Issue      | Ongoing criminal investigation for money laundering     |\n",
    "| Ongoing Risk?           | Yes (as of 2025-09-16)                                  |\n",
    "| Investigating Authority | Moldovan law enforcement                                |\n",
    "| Geographic Spread       | Moldova only                                            |\n",
    "| Settlement Efforts      | None reported                                           |\n",
    "| Risk Rating             | HIGH                                                    |\n",
    "| Recommendation          | AVOID PARTNERSHIP                                       |\n",
    "\n",
    "    \"\"\")\n",
    "    \n",
    "    # Prepare evidence for analysis\n",
    "    # Build evidence_prompt dynamically (no hardcoded claim types)\n",
    "    sections = []\n",
    "    for t in sorted(claims_by_type.keys()):\n",
    "        items = claims_by_type[t]\n",
    "        if not items:\n",
    "            continue\n",
    "        title = t.replace(\"_\", \" \").upper()  # simple, generic prettifier\n",
    "        sections.append(f\"{title}:\\n{json.dumps(items, indent=2, ensure_ascii=False)}\")\n",
    "\n",
    "    evidence_block = \"\\n\\n\".join(sections) if sections else \"No evidence available.\"\n",
    "\n",
    "    evidence_prompt = (\n",
    "        f\"Evidence for {entity_name}:\\n\\n\"\n",
    "        f\"{evidence_block}\\n\\n\"\n",
    "        \"Based on this evidence:\\n\"\n",
    "        \"1. Calculate the total fines paid\\n\"\n",
    "        \"2. Identify the most serious issue (hint: look for large transaction amounts)\\n\"\n",
    "        \"3. Determine if this is historical or ongoing risk\\n\"\n",
    "        \"4. Make your partnership recommendation with clear reasoning\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"Request LLM Response \")\n",
    "    print(\"Example of evidence_prompt: \", evidence_prompt)\n",
    "    messages = [system_message, HumanMessage(content=evidence_prompt)]\n",
    "\n",
    "    analysis_response = llm_evaluation.invoke(messages)\n",
    "    \n",
    "    print(\"Risk assessment completed\")\n",
    "    return {\"messages\": [analysis_response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b749d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add node to the workflow \n",
    "\n",
    "\n",
    "# assemble agent\n",
    "builder = StateGraph(UnifiedResearchState)\n",
    "\n",
    "# content extraction\n",
    "builder.add_node( \"llm\", llm_node)\n",
    "builder.add_node( \"tool_node_chunk_selection_exec\", tool_node_chunk_selection_exec)\n",
    "builder.add_node( \"extract_content\", extract_content)\n",
    "builder.add_node( \"generate_risk_assessment\", generate_risk_assessment)\n",
    "builder.add_node( \"filter_relevant_content\",filter_relevant_content)\n",
    "  # the node DOES wait for all incoming edges to complete before\n",
    "\n",
    "# hyde generation\n",
    "builder.add_node( \"create_journalists\", create_journalists )\n",
    "builder.add_node( \"generate_hyde_document\", generate_hyde_document )\n",
    "\n",
    "# estimate score \n",
    "builder.add_node( \"assign_score_vs_hyde\" ,  assign_score_vs_hyde )\n",
    "\n",
    "# evidence assessment \n",
    "builder.add_node( \"extract_evidence_claims\", extract_evidence_claims)\n",
    "\n",
    "# logic \n",
    "\n",
    "# content extraction\n",
    "builder.add_edge(START, \"llm\")\n",
    "builder.add_edge( \"llm\", \"tool_node_chunk_selection_exec\")\n",
    "builder.add_edge( \"tool_node_chunk_selection_exec\", \"extract_content\")\n",
    "builder.add_edge( \"extract_content\", \"assign_score_vs_hyde\")  # Then end\n",
    "\n",
    "# article writer\n",
    "builder.add_edge( \"llm\" , \"create_journalists\")\n",
    "builder.add_edge( \"create_journalists\" , \"generate_hyde_document\")\n",
    "builder.add_edge( \"generate_hyde_document\" , \"assign_score_vs_hyde\" )\n",
    "builder.add_edge( \"assign_score_vs_hyde\" , \"filter_relevant_content\" )\n",
    "builder.add_edge( \"filter_relevant_content\" , \"extract_evidence_claims\" )\n",
    "builder.add_edge( \"extract_evidence_claims\" , \"generate_risk_assessment\" )\n",
    "builder.add_edge(\"generate_risk_assessment\", END)  # Then end\n",
    "\n",
    "# assemble agent\n",
    "graph = builder.compile( )\n",
    "\n",
    "mermaid_code = graph.get_graph(xray=True).draw_mermaid()\n",
    "render_mermaid_graph(mermaid_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test \n",
    "# Moldretail\n",
    "# Lukoil  Wachovia Bank     HSBC    Dankse Bank Moldindconbank\n",
    "# Finpar Invest\n",
    "# trans oil\n",
    "# danube logistics\n",
    "\n",
    "# try different search algoriths\n",
    "# LLM as local \n",
    "# juridical cases in pdf , justice md\n",
    "\n",
    "initial_message = [ HumanMessage(content = \"Lukoil\" )  ]\n",
    "results = graph.invoke(   \n",
    "               {\n",
    "                    \"messages\" : initial_message,\n",
    "                    \"max_journalists\": 5,\n",
    "                    \"journalists\": [],  # Will be populated by create_journalists node\n",
    "                    \"hyde_list\": []     # Will be populated by generate_hyde_document node\n",
    "                    \n",
    "                } )\n",
    "# \"max_journalists\": 6, 10 links per language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c136e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_res = results.get(\"messages\", None)\n",
    "print( summary_res[-1].content )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56abc83c",
   "metadata": {},
   "source": [
    "#### Select components to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa2bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data used for the conclusion\n",
    "evidence_collection = [] \n",
    "for elem in results.get(\"search_results_raw\"):\n",
    "    if elem.summary:\n",
    "        out = elem.model_dump( exclude={\"raw_content\", \"hyde_score\"} )\n",
    "        evidence_collection.append(out)\n",
    "        \n",
    "evidence_collection    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e268b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data used for the conclusion\n",
    "evidence_collection = [] \n",
    "for elem in results.get(\"search_results\"):\n",
    "    if elem.summary:\n",
    "        out = elem.model_dump( exclude={\"raw_content\", \"hyde_score\"} )\n",
    "        evidence_collection.append(out)\n",
    "        \n",
    "evidence_collection    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_collection = []\n",
    "for elem in results.get(\"evidence_claims\"):\n",
    "        out = elem.model_dump()\n",
    "        links_collection.append(out)\n",
    "        \n",
    "links_collection        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_res = results.get(\"messages\", None)\n",
    "print( summary_res[-1].content )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e1b15a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
